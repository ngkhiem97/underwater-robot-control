{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and generation of experience data collected from the simulation\n",
    "\n",
    "## 1. Import and filter data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: \n",
      "(6330, 40)\n",
      "after: \n",
      "(4698, 42)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/exp.csv', header=None)\n",
    "\n",
    "# print shape of the dataframe\n",
    "print(\"before: \")\n",
    "print(df.shape)\n",
    "\n",
    "# information of the dataframe\n",
    "# 0-11: obs\n",
    "# 12-14: achieved_goal\n",
    "# 15-17: desired_goal\n",
    "# 18-20: action\n",
    "# 21: reward\n",
    "# 22-33: next_obs\n",
    "# 34-36: next_achieved_goal\n",
    "# 37-39: next_desired_goal\n",
    "\n",
    "# make last column to be the distance between obs and next_obs\n",
    "df[40] = ((df[0] - df[22])**2 + (df[1] - df[23])**2 + (df[2] - df[24])**2)**0.5\n",
    "\n",
    "# make last column to be the distance between desired_goal and next_desired_goal\n",
    "df[41] = ((df[15] - df[37])**2 + (df[16] - df[38])**2 + (df[17] - df[39])**2)**0.5\n",
    "\n",
    "# remove rows that has distance < 0.01\n",
    "df = df[df[40] > 0.01]\n",
    "df = df[df[40] < 0.2]\n",
    "\n",
    "# remove rows that has distance > 0.1\n",
    "df = df[df[41] < 0.05]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "# plot the distribution of column 37\n",
    "df[40].hist(bins=100, ax=ax[0])\n",
    "\n",
    "# plot the distribution of column 38\n",
    "df[41].hist(bins=100, ax=ax[1])\n",
    "\n",
    "print(\"after: \")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a linear question model in order to predict the next gripper position based on the selected action and the original gripper position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9501045221067054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff773c983d0>,\n",
       " <matplotlib.lines.Line2D at 0x7ff773c98460>,\n",
       " <matplotlib.lines.Line2D at 0x7ff773c98490>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grip_pos = df[[0, 1, 2]]\n",
    "grip_pos_next = df[[22, 23, 24]].rename(columns={22: 0, 23: 1, 24: 2})\n",
    "action = df[[18, 19, 20]].rename(columns={18: 3, 19: 4, 20: 5})\n",
    "\n",
    "# seperate the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "grip_pos_train, grip_pos_test, grip_pos_next_train, grip_pos_next_test, action_train, action_test = train_test_split(grip_pos, grip_pos_next, action, test_size=0.2, random_state=42)\n",
    "\n",
    "# # use linear regression to predict the next grip position\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg1 = LinearRegression().fit(grip_pos_train.join(action_train), grip_pos_next_train)\n",
    "\n",
    "# print the score\n",
    "print(reg1.score(grip_pos_test.join(action_test), grip_pos_next_test))\n",
    "\n",
    "pred = reg1.predict(grip_pos_test.join(action_test))\n",
    "actual = grip_pos_next_test\n",
    "\n",
    "# reset index of actual to 0 to len(actual)\n",
    "actual = actual.reset_index(drop=True)\n",
    "\n",
    "# plot the results\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(actual[:100], label='actual')\n",
    "plt.plot(pred[:100], label='pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a linear regression model in order to predict the next target position based on the target relative position and the target original position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff773f87610>,\n",
       " <matplotlib.lines.Line2D at 0x7ff773f876a0>,\n",
       " <matplotlib.lines.Line2D at 0x7ff773f876d0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_pos = df[[3, 4, 5]].rename(columns={3: 0, 4: 1, 5: 2})\n",
    "target_pos_next = df[[25, 26, 27]].rename(columns={25: 0, 26: 1, 27: 2})\n",
    "target_rel_vel = df[[9, 10, 11]].rename(columns={9: 3, 10: 4, 11: 5})\n",
    "\n",
    "# seperate the data into training and testing\n",
    "target_pos_train, target_pos_test, target_pos_next_train, target_pos_next_test, target_rel_vel_train, target_rel_vel_test = train_test_split(target_pos, target_pos_next, target_rel_vel, test_size=0.2, random_state=42)\n",
    "\n",
    "# use linear regression to predict the next position of the target from the current position and relative velocity\n",
    "reg2 = LinearRegression().fit(target_pos_train.join(target_rel_vel_train), target_pos_next_train)\n",
    "\n",
    "# predict the next position of the target from the current position and relative velocity\n",
    "target_pos_next_pred = reg2.predict(target_pos_test.join(target_rel_vel_test))\n",
    "pred = target_pos_next_pred\n",
    "actual = target_pos_next_test\n",
    "actual = actual.reset_index(drop=True)\n",
    "\n",
    "# plot the result\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(actual[:50], label='actual')\n",
    "plt.plot(pred[:50], label='pred')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate more data for the gripper position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grip_pos_min:  0   -0.240712\n",
      "1    0.682863\n",
      "2   -0.007917\n",
      "dtype: float64\n",
      "grip_pos_max:  0    0.301259\n",
      "1    1.273924\n",
      "2    0.430296\n",
      "dtype: float64\n",
      "action_min:  [-0.99948627 -1.         -0.9994843 ]\n",
      "action_max:  [1.         0.99786431 1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff773e26bc0>,\n",
       " <matplotlib.lines.Line2D at 0x7ff773e26c20>,\n",
       " <matplotlib.lines.Line2D at 0x7ff773e26c50>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get min max of grip_pos\n",
    "grip_pos_min = grip_pos.min()\n",
    "grip_pos_max = grip_pos.max()\n",
    "action_min = action.min()\n",
    "action_max = action.max()\n",
    "\n",
    "# reshape action_min from (3, 1) to (3, )\n",
    "action_min = action_min.values.reshape(3, )\n",
    "action_max = action_max.values.reshape(3, )\n",
    "\n",
    "print(\"grip_pos_min: \", grip_pos_min)\n",
    "print(\"grip_pos_max: \", grip_pos_max)\n",
    "print(\"action_min: \", action_min)\n",
    "print(\"action_max: \", action_max)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# generate random grip_pos \n",
    "grip_pos_random = np.random.uniform(grip_pos_min, grip_pos_max, size=(255555, 3))\n",
    "grip_pos_random = pd.DataFrame(grip_pos_random)\n",
    "\n",
    "# generate random action\n",
    "action_random = np.random.uniform(action_min, action_max, size=(255555, 3))\n",
    "action_random = pd.DataFrame(action_random).rename(columns={0: 3, 1: 4, 2: 5})\n",
    "\n",
    "# predict the next grip_pos\n",
    "grip_pos_next = reg1.predict(grip_pos_random.join(action_random))\n",
    "\n",
    "# plot grip_pos_next\n",
    "fig = plt.figure()\n",
    "plt.plot(grip_pos_next, label='grip_pos_next')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate more data for the target position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_pos_min:  0   -0.322565\n",
      "1    0.008043\n",
      "2    0.387963\n",
      "dtype: float64\n",
      "target_pos_max:  0    0.335776\n",
      "1    1.343505\n",
      "2    0.975013\n",
      "dtype: float64\n",
      "target_rel_vel_min:  3   -0.666875\n",
      "4   -0.707960\n",
      "5   -1.136060\n",
      "dtype: float64\n",
      "target_rel_vel_max:  3    0.537654\n",
      "4    0.940969\n",
      "5    0.645404\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff773ec13f0>,\n",
       " <matplotlib.lines.Line2D at 0x7ff773ec1450>,\n",
       " <matplotlib.lines.Line2D at 0x7ff773ec1480>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_pos_min = target_pos.min()\n",
    "target_pos_max = target_pos.max()\n",
    "target_rel_vel_min = target_rel_vel.min()\n",
    "target_rel_vel_max = target_rel_vel.max()\n",
    "\n",
    "print(\"target_pos_min: \", target_pos_min)\n",
    "print(\"target_pos_max: \", target_pos_max)\n",
    "print(\"target_rel_vel_min: \", target_rel_vel_min)\n",
    "print(\"target_rel_vel_max: \", target_rel_vel_max)\n",
    "\n",
    "# generate random target_pos\n",
    "target_pos_random = np.random.uniform(target_pos_min, target_pos_max, (255555, 3))\n",
    "target_pos_random = pd.DataFrame(target_pos_random)\n",
    "\n",
    "# generate random target_rel_vel\n",
    "target_rel_vel_random = np.random.uniform(target_rel_vel_min, target_rel_vel_max, (255555, 3))\n",
    "target_rel_vel_random = pd.DataFrame(target_rel_vel_random).rename(columns={0: 3, 1: 4, 2: 5})\n",
    "\n",
    "# predict the next target_pos\n",
    "target_pos_next_pred = reg2.predict(target_pos_random.join(target_rel_vel_random))\n",
    "pred = target_pos_next_pred\n",
    "\n",
    "# plot the prediction\n",
    "fig = plt.figure()\n",
    "plt.plot(pred, label='target_pos_next_pred')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combine the generated features to make a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grip_pos_random = grip_pos_random.rename(columns={0: 0, 1: 1, 2: 2}).reset_index(drop=True)\n",
    "target_pos_random = target_pos_random.rename(columns={0: 3, 1: 4, 2: 5}).reset_index(drop=True)\n",
    "delta_pos = target_pos_random.rename(columns={3: 0, 4: 1, 5: 2}) - grip_pos_random\n",
    "delta_pos = delta_pos.rename(columns={0: 6, 1: 7, 2: 8}).reset_index(drop=True)\n",
    "target_rel_vel_random = target_rel_vel_random.rename(columns={3: 9, 4: 10, 5: 11}).reset_index(drop=True)\n",
    "achieved_goal = grip_pos_random.rename(columns={0: 12, 1: 13, 2: 14})\n",
    "goal = target_pos_random.rename(columns={3: 15, 4: 16, 5: 17})\n",
    "action = action_random.rename(columns={3: 18, 4: 19, 5: 20})\n",
    "grip_pos_next = pd.DataFrame(grip_pos_next).rename(columns={0: 22, 1: 23, 2: 24}).reset_index(drop=True)\n",
    "target_pos_random_next = pd.DataFrame(target_pos_next_pred).rename(columns={0: 25, 1: 26, 2: 27}).reset_index(drop=True)\n",
    "delta_pos_next = target_pos_random_next.rename(columns={25: 0, 26: 1, 27: 2}) - grip_pos_next.rename(columns={22: 0, 23: 1, 24: 2})\n",
    "delta_pos_next = delta_pos_next.rename(columns={0: 28, 1: 29, 2: 30}).reset_index(drop=True)\n",
    "target_rel_vel_random_next = target_rel_vel_random.rename(columns={3: 31, 4: 32, 5: 33}).reset_index(drop=True)\n",
    "achieved_goal_next = grip_pos_next.rename(columns={22: 34, 23: 35, 24: 36})\n",
    "REWARD_SCALE=10.0\n",
    "reward = pd.DataFrame(-np.linalg.norm(delta_pos_next.to_numpy(), axis=-1)/REWARD_SCALE).rename(columns={0: 21})\n",
    "\n",
    "# concat all the data\n",
    "new_data = pd.concat([grip_pos_random, target_pos_random, delta_pos, target_rel_vel_random, achieved_goal, goal, action, reward, grip_pos_next, target_pos_random_next, delta_pos_next, target_rel_vel_random_next, achieved_goal_next, target_pos_random_next], axis=1)\n",
    "new_data = new_data.reset_index(drop=True).to_numpy()\n",
    "\n",
    "# remove original calculated distance\n",
    "old_data = df.reset_index(drop=True).to_numpy()\n",
    "old_data = np.delete(old_data, [40, 41], axis=1)\n",
    "# concat new data and old data\n",
    "new_data = np.concatenate((old_data, new_data), axis=0)\n",
    "# export to csv\n",
    "np.savetxt(\"./data/gen_data.csv\", new_data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the original model with the new dataset\n",
    "\n",
    "First, specify the path to the model file, and select if HER sampler is used or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models/UnderwaterEnv/model_default_epoch41_2023-08-26-10-02-11.pt'\n",
    "her_used = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define neccessary functions for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khiem/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-26 19:31:54.399769: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/khiem/miniconda3/lib/:/home/khiem/miniconda3/lib/\n",
      "2023-08-26 19:31:54.400038: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/khiem/miniconda3/lib/:/home/khiem/miniconda3/lib/\n",
      "2023-08-26 19:31:54.400062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> with i =  0\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[0.1493],\n",
      "        [0.1919],\n",
      "        [0.1611],\n",
      "        [0.1497]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[0.0166, 0.0425, 0.0785],\n",
      "        [0.0046, 0.0597, 0.0439],\n",
      "        [0.0625, 0.0703, 0.0227],\n",
      "        [0.0626, 0.0751, 0.0557]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "---> with i =  20_loss:  0.05490139126777649  critic_loss:  0.0070820637047290823\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[0.0577],\n",
      "        [0.0126],\n",
      "        [0.0627],\n",
      "        [0.0396]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.1845, -0.3629,  0.0797],\n",
      "        [-0.0941, -0.2267, -0.1454],\n",
      "        [ 0.0172, -0.1924, -0.2346],\n",
      "        [-0.0561, -0.2509, -0.2509]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  40_loss:  0.05892476439476013  critic_loss:  0.0018591203261166816\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0470],\n",
      "        [-0.0168],\n",
      "        [-0.0303],\n",
      "        [-0.0227]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5353, -0.7152,  0.5844],\n",
      "        [-0.5010, -0.7032,  0.4930],\n",
      "        [-0.3332, -0.6590,  0.3835],\n",
      "        [-0.3486, -0.7124,  0.3913]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  60_loss:  0.06224662810564041  critic_loss:  0.00092002225574105985\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-2.7618e-02],\n",
      "        [-8.2613e-03],\n",
      "        [-8.3357e-05],\n",
      "        [ 1.8220e-03]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6951, -0.9356,  0.8766],\n",
      "        [-0.6336, -0.9253,  0.8703],\n",
      "        [-0.5576, -0.9025,  0.8491],\n",
      "        [-0.5926, -0.9113,  0.8780]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  80_loss:  0.06506910175085068  critic_loss:  0.00049134256551042255\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0216],\n",
      "        [-0.0036],\n",
      "        [ 0.0020],\n",
      "        [ 0.0043]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6266, -0.9511,  0.8980],\n",
      "        [-0.5615, -0.9398,  0.8408],\n",
      "        [-0.4718, -0.9324,  0.8709],\n",
      "        [-0.5185, -0.9375,  0.9028]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  100loss:  0.06752471625804901  critic_loss:  0.00027148751541972166\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0226],\n",
      "        [-0.0017],\n",
      "        [-0.0040],\n",
      "        [-0.0009]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9318, -0.9942,  0.9706],\n",
      "        [-0.9246, -0.9924,  0.9595],\n",
      "        [-0.8444, -0.9899,  0.9784],\n",
      "        [-0.8699, -0.9914,  0.9847]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  120_loss:  0.06970714777708054  critic_loss:  0.00017197689157910645\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0202],\n",
      "        [-0.0050],\n",
      "        [-0.0058],\n",
      "        [-0.0035]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9187, -0.9962,  0.9912],\n",
      "        [-0.8967, -0.9936,  0.9914],\n",
      "        [-0.8209, -0.9906,  0.9954],\n",
      "        [-0.8599, -0.9920,  0.9971]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  140_loss:  0.06989893317222595  critic_loss:  0.00011639915464911611\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0188],\n",
      "        [-0.0103],\n",
      "        [-0.0080],\n",
      "        [-0.0057]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7482, -0.9953,  0.9935],\n",
      "        [-0.7360, -0.9923,  0.9928],\n",
      "        [-0.6094, -0.9871,  0.9949],\n",
      "        [-0.6790, -0.9892,  0.9969]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  160_loss:  0.07014469802379608  critic_loss:  8.4393032011576e-05053\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0186],\n",
      "        [-0.0144],\n",
      "        [-0.0106],\n",
      "        [-0.0104]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6928, -0.9947,  0.9913],\n",
      "        [-0.6254, -0.9921,  0.9914],\n",
      "        [-0.4572, -0.9836,  0.9948],\n",
      "        [-0.4786, -0.9860,  0.9955]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  180_loss:  0.07061794400215149  critic_loss:  6.304858106886968e-05\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0185],\n",
      "        [-0.0133],\n",
      "        [-0.0090],\n",
      "        [-0.0083]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7613, -0.9947,  0.9842],\n",
      "        [-0.7006, -0.9930,  0.9845],\n",
      "        [-0.5137, -0.9872,  0.9909],\n",
      "        [-0.5347, -0.9887,  0.9904]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  200_loss:  0.07113200426101685  critic_loss:  4.8252295528072864e-05\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0095],\n",
      "        [-0.0058],\n",
      "        [-0.0063]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6197, -0.9873,  0.9785],\n",
      "        [-0.4732, -0.9886,  0.9772],\n",
      "        [-0.4645, -0.9810,  0.9838],\n",
      "        [-0.4539, -0.9823,  0.9826]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  220_loss:  0.07176082581281662  critic_loss:  3.774209471885115e-055\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0088],\n",
      "        [-0.0041],\n",
      "        [-0.0119]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6328, -0.9601,  0.9509],\n",
      "        [-0.5582, -0.9643,  0.9728],\n",
      "        [-0.5688, -0.9430,  0.9750],\n",
      "        [-0.5847, -0.9366,  0.9805]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  240_loss:  0.07137502729892731  critic_loss:  3.0134377084323205e-05\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0190],\n",
      "        [-0.0135],\n",
      "        [-0.0123],\n",
      "        [-0.0184]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6957, -0.9720,  0.8928],\n",
      "        [-0.6896, -0.9684,  0.9449],\n",
      "        [-0.5929, -0.9449,  0.9588],\n",
      "        [-0.6402, -0.9496,  0.9673]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  260_loss:  0.07154897600412369  critic_loss:  2.50941957347095e-0555\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0197],\n",
      "        [-0.0137],\n",
      "        [-0.0142],\n",
      "        [-0.0199]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7302, -0.9817,  0.8374],\n",
      "        [-0.7403, -0.9761,  0.8879],\n",
      "        [-0.5766, -0.9558,  0.9198],\n",
      "        [-0.6316, -0.9591,  0.9331]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  280_loss:  0.0720762088894844  critic_loss:  2.171170308429282e-0505\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0195],\n",
      "        [-0.0128],\n",
      "        [-0.0141],\n",
      "        [-0.0201]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7016, -0.9858,  0.7750],\n",
      "        [-0.6934, -0.9801,  0.8378],\n",
      "        [-0.4990, -0.9591,  0.8555],\n",
      "        [-0.5669, -0.9585,  0.8674]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  300_loss:  0.07181945443153381  critic_loss:  1.9042161511606537e-05\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0197],\n",
      "        [-0.0128],\n",
      "        [-0.0142],\n",
      "        [-0.0209]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6849, -0.9871,  0.7353],\n",
      "        [-0.6506, -0.9839,  0.8029],\n",
      "        [-0.4419, -0.9593,  0.7882],\n",
      "        [-0.5172, -0.9578,  0.8018]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  320_loss:  0.07163995504379272  critic_loss:  1.716961560305208e-055\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0200],\n",
      "        [-0.0131],\n",
      "        [-0.0147],\n",
      "        [-0.0206]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6725, -0.9879,  0.7330],\n",
      "        [-0.6296, -0.9861,  0.8096],\n",
      "        [-0.4255, -0.9546,  0.7627],\n",
      "        [-0.4892, -0.9527,  0.8036]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  340_loss:  0.07234907150268555  critic_loss:  1.5727155187050812e-05\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0193],\n",
      "        [-0.0119],\n",
      "        [-0.0136],\n",
      "        [-0.0187]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6424, -0.9868,  0.7608],\n",
      "        [-0.6050, -0.9858,  0.8135],\n",
      "        [-0.4350, -0.9392,  0.7548],\n",
      "        [-0.4872, -0.9389,  0.7944]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  360_loss:  0.07196713984012604  critic_loss:  1.4332757018564735e-05\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0193],\n",
      "        [-0.0123],\n",
      "        [-0.0142],\n",
      "        [-0.0187]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6260, -0.9825,  0.7822],\n",
      "        [-0.6147, -0.9818,  0.8124],\n",
      "        [-0.4509, -0.9081,  0.7401],\n",
      "        [-0.5042, -0.9057,  0.7956]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  380_loss:  0.07173345983028412  critic_loss:  1.3389797459240071e-05\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0192],\n",
      "        [-0.0129],\n",
      "        [-0.0149],\n",
      "        [-0.0188]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6383, -0.9741,  0.7834],\n",
      "        [-0.6184, -0.9767,  0.8014],\n",
      "        [-0.4810, -0.8544,  0.7334],\n",
      "        [-0.5296, -0.8527,  0.7829]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  400_loss:  0.07181660830974579  critic_loss:  1.249179695150815e-055\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0186],\n",
      "        [-0.0127],\n",
      "        [-0.0147],\n",
      "        [-0.0183]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6357, -0.9588,  0.7989],\n",
      "        [-0.5980, -0.9687,  0.8057],\n",
      "        [-0.4820, -0.7746,  0.7449],\n",
      "        [-0.5274, -0.7719,  0.7904]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  420_loss:  0.07178876549005508  critic_loss:  1.1744158655346837e-05\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0184],\n",
      "        [-0.0130],\n",
      "        [-0.0149],\n",
      "        [-0.0181]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6228, -0.9431,  0.8218],\n",
      "        [-0.5728, -0.9598,  0.8323],\n",
      "        [-0.4838, -0.7116,  0.7603],\n",
      "        [-0.5067, -0.6893,  0.8079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  440_loss:  0.0717589408159256  critic_loss:  1.1110455488960724e-055\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0179],\n",
      "        [-0.0131],\n",
      "        [-0.0147],\n",
      "        [-0.0176]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6158, -0.9123,  0.7964],\n",
      "        [-0.5575, -0.9376,  0.8345],\n",
      "        [-0.5090, -0.6315,  0.7044],\n",
      "        [-0.5103, -0.5780,  0.7797]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  460_loss:  0.07181519269943237  critic_loss:  1.0537596608628519e-05\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0178],\n",
      "        [-0.0136],\n",
      "        [-0.0153],\n",
      "        [-0.0177]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6193, -0.8357,  0.7701],\n",
      "        [-0.5647, -0.8876,  0.8241],\n",
      "        [-0.5347, -0.4614,  0.6139],\n",
      "        [-0.5481, -0.4022,  0.7242]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  480_loss:  0.07196441292762756  critic_loss:  1.0008378012571484e-05\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0173],\n",
      "        [-0.0137],\n",
      "        [-0.0149],\n",
      "        [-0.0172]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6102, -0.7934,  0.7722],\n",
      "        [-0.5460, -0.8612,  0.8360],\n",
      "        [-0.5219, -0.3972,  0.6055],\n",
      "        [-0.5454, -0.3501,  0.7251]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  500_loss:  0.07202043384313583  critic_loss:  9.560226317262277e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0146],\n",
      "        [-0.0170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6191, -0.7700,  0.7828],\n",
      "        [-0.5634, -0.8418,  0.8431],\n",
      "        [-0.5493, -0.3737,  0.5941],\n",
      "        [-0.5720, -0.3245,  0.7222]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  520_loss:  0.07232625782489777  critic_loss:  9.38172252062941e-0665\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0135],\n",
      "        [-0.0140],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6174, -0.7641,  0.7988],\n",
      "        [-0.5675, -0.8358,  0.8546],\n",
      "        [-0.5428, -0.3602,  0.6170],\n",
      "        [-0.5655, -0.3103,  0.7424]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  540_loss:  0.07194443047046661  critic_loss:  8.809669452602975e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0137],\n",
      "        [-0.0144],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6097, -0.7609,  0.8098],\n",
      "        [-0.5771, -0.8337,  0.8680],\n",
      "        [-0.5259, -0.3424,  0.6587],\n",
      "        [-0.5456, -0.2805,  0.7751]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  560_loss:  0.07168003171682358  critic_loss:  8.468910891679116e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0140],\n",
      "        [-0.0147],\n",
      "        [-0.0171]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6038, -0.7486,  0.8054],\n",
      "        [-0.5755, -0.8207,  0.8726],\n",
      "        [-0.5177, -0.3156,  0.6585],\n",
      "        [-0.5418, -0.2534,  0.7767]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  580_loss:  0.07168074697256088  critic_loss:  8.162551239365712e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0139],\n",
      "        [-0.0145],\n",
      "        [-0.0170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6240, -0.7391,  0.8009],\n",
      "        [-0.5927, -0.8110,  0.8704],\n",
      "        [-0.5388, -0.3021,  0.6432],\n",
      "        [-0.5677, -0.2438,  0.7597]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  600_loss:  0.07093218713998795  critic_loss:  8.449472261418123e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0174],\n",
      "        [-0.0151],\n",
      "        [-0.0158],\n",
      "        [-0.0183]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6250, -0.7368,  0.7952],\n",
      "        [-0.5838, -0.8112,  0.8735],\n",
      "        [-0.5385, -0.3105,  0.6548],\n",
      "        [-0.5687, -0.2536,  0.7634]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  620_loss:  0.07205452024936676  critic_loss:  7.797557373123709e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0136],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6426, -0.7264,  0.7982],\n",
      "        [-0.5995, -0.8087,  0.8757],\n",
      "        [-0.5582, -0.2919,  0.6699],\n",
      "        [-0.5884, -0.2378,  0.7740]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  640_loss:  0.0715961903333664  critic_loss:  7.431032372551272e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0138],\n",
      "        [-0.0144],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6315, -0.7262,  0.7998],\n",
      "        [-0.5846, -0.8058,  0.8811],\n",
      "        [-0.5632, -0.2911,  0.6841],\n",
      "        [-0.5921, -0.2432,  0.7803]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  660_loss:  0.07168814539909363  critic_loss:  7.229835318867117e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0137],\n",
      "        [-0.0142],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6267, -0.7265,  0.8118],\n",
      "        [-0.5748, -0.8063,  0.8897],\n",
      "        [-0.5723, -0.3024,  0.6953],\n",
      "        [-0.6017, -0.2571,  0.7863]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  680_loss:  0.07157956063747406  critic_loss:  7.036340321064927e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0137],\n",
      "        [-0.0143],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6161, -0.7362,  0.8136],\n",
      "        [-0.5559, -0.8178,  0.8888],\n",
      "        [-0.5608, -0.3169,  0.7048],\n",
      "        [-0.5892, -0.2780,  0.7886]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  700_loss:  0.07085707038640976  critic_loss:  7.371791980403941e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0150],\n",
      "        [-0.0155],\n",
      "        [-0.0179]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5806, -0.7551,  0.8265],\n",
      "        [-0.5026, -0.8342,  0.8971],\n",
      "        [-0.5132, -0.3470,  0.7314],\n",
      "        [-0.5411, -0.3193,  0.8056]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  720_loss:  0.07198277115821838  critic_loss:  6.880030923639424e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0136],\n",
      "        [-0.0142],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5790, -0.7654,  0.8389],\n",
      "        [-0.4923, -0.8454,  0.9033],\n",
      "        [-0.5104, -0.3614,  0.7461],\n",
      "        [-0.5419, -0.3410,  0.8165]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  740_loss:  0.07167427241802216  critic_loss:  6.577990006917389e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0138],\n",
      "        [-0.0143],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5497, -0.7700,  0.8398],\n",
      "        [-0.4603, -0.8482,  0.9093],\n",
      "        [-0.4721, -0.3725,  0.7488],\n",
      "        [-0.5167, -0.3664,  0.8199]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  760_loss:  0.07160696387290955  critic_loss:  6.433499038394075e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0157],\n",
      "        [-0.0137],\n",
      "        [-0.0143],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5457, -0.7823,  0.8455],\n",
      "        [-0.4567, -0.8582,  0.9163],\n",
      "        [-0.4567, -0.4015,  0.7589],\n",
      "        [-0.5184, -0.4093,  0.8302]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  780_loss:  0.07150311768054962  critic_loss:  6.3010047597344965e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0139],\n",
      "        [-0.0144],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5426, -0.7776,  0.8513],\n",
      "        [-0.4609, -0.8546,  0.9220],\n",
      "        [-0.4620, -0.4005,  0.7700],\n",
      "        [-0.5235, -0.4094,  0.8373]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  800_loss:  0.07150766253471375  critic_loss:  6.177942850627005e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0139],\n",
      "        [-0.0144],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5367, -0.7851,  0.8482],\n",
      "        [-0.4627, -0.8600,  0.9211],\n",
      "        [-0.4693, -0.4163,  0.7624],\n",
      "        [-0.5282, -0.4246,  0.8307]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  820_loss:  0.07152791321277618  critic_loss:  6.060903160687303e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0157],\n",
      "        [-0.0139],\n",
      "        [-0.0144],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5306, -0.7973,  0.8493],\n",
      "        [-0.4645, -0.8683,  0.9239],\n",
      "        [-0.4806, -0.4420,  0.7695],\n",
      "        [-0.5297, -0.4459,  0.8330]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  840_loss:  0.07252084463834763  critic_loss:  6.950044735276606e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0145],\n",
      "        [-0.0124],\n",
      "        [-0.0129],\n",
      "        [-0.0148]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5195, -0.7952,  0.8497],\n",
      "        [-0.4586, -0.8658,  0.9251],\n",
      "        [-0.4863, -0.4512,  0.7704],\n",
      "        [-0.5208, -0.4427,  0.8325]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  860_loss:  0.07112764567136765  critic_loss:  5.993724244035548e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0147],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5218, -0.7991,  0.8550],\n",
      "        [-0.4635, -0.8672,  0.9293],\n",
      "        [-0.4993, -0.4666,  0.7784],\n",
      "        [-0.5253, -0.4494,  0.8388]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  880_loss:  0.07133395224809647  critic_loss:  5.785329904028913e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0146],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5096, -0.7951,  0.8595],\n",
      "        [-0.4556, -0.8632,  0.9327],\n",
      "        [-0.4978, -0.4601,  0.7819],\n",
      "        [-0.5187, -0.4383,  0.8421]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  900_loss:  0.07148950546979904  critic_loss:  5.6647841120138764e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0140],\n",
      "        [-0.0145],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5009, -0.7980,  0.8663],\n",
      "        [-0.4548, -0.8626,  0.9355],\n",
      "        [-0.5043, -0.4572,  0.7878],\n",
      "        [-0.5187, -0.4325,  0.8498]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  920_loss:  0.07147946208715439  critic_loss:  5.575695467996411e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0157],\n",
      "        [-0.0140],\n",
      "        [-0.0145],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4910, -0.8045,  0.8725],\n",
      "        [-0.4513, -0.8655,  0.9364],\n",
      "        [-0.5100, -0.4639,  0.7890],\n",
      "        [-0.5165, -0.4322,  0.8539]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  940_loss:  0.07148347795009613  critic_loss:  5.489408977155108e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0140],\n",
      "        [-0.0145],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4830, -0.8052,  0.8771],\n",
      "        [-0.4487, -0.8658,  0.9380],\n",
      "        [-0.5171, -0.4562,  0.7928],\n",
      "        [-0.5185, -0.4149,  0.8566]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  960_loss:  0.07147965580224991  critic_loss:  5.4059200920164585e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0141],\n",
      "        [-0.0145],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4820, -0.8067,  0.8824],\n",
      "        [-0.4523, -0.8661,  0.9393],\n",
      "        [-0.5277, -0.4487,  0.7960],\n",
      "        [-0.5278, -0.4005,  0.8578]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  980_loss:  0.07139056921005249  critic_loss:  5.3321859923016746e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0147],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4775, -0.8085,  0.8900],\n",
      "        [-0.4483, -0.8660,  0.9404],\n",
      "        [-0.5299, -0.4570,  0.7968],\n",
      "        [-0.5298, -0.4046,  0.8570]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1000loss:  0.07166381180286407  critic_loss:  5.2981813496444374e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0145],\n",
      "        [-0.0150],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4843, -0.8209,  0.9015],\n",
      "        [-0.4533, -0.8716,  0.9460],\n",
      "        [-0.5382, -0.4784,  0.8096],\n",
      "        [-0.5387, -0.4272,  0.8669]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1020_loss:  0.07132390886545181  critic_loss:  5.2070240599277895e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0144],\n",
      "        [-0.0148],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4812, -0.8136,  0.9014],\n",
      "        [-0.4538, -0.8656,  0.9439],\n",
      "        [-0.5423, -0.4578,  0.7987],\n",
      "        [-0.5439, -0.4076,  0.8604]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1040_loss:  0.07140489667654037  critic_loss:  5.1208494369348045e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0146],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4710, -0.8056,  0.9021],\n",
      "        [-0.4475, -0.8586,  0.9454],\n",
      "        [-0.5406, -0.4461,  0.8007],\n",
      "        [-0.5434, -0.3952,  0.8624]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1060_loss:  0.07149020582437515  critic_loss:  5.0505523176980205e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0141],\n",
      "        [-0.0145],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4656, -0.8066,  0.9006],\n",
      "        [-0.4431, -0.8543,  0.9455],\n",
      "        [-0.5394, -0.4477,  0.7987],\n",
      "        [-0.5437, -0.3970,  0.8619]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1080_loss:  0.0714569166302681  critic_loss:  4.985721716366243e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0141],\n",
      "        [-0.0145],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4664, -0.7997,  0.9025],\n",
      "        [-0.4415, -0.8464,  0.9459],\n",
      "        [-0.5371, -0.4321,  0.7992],\n",
      "        [-0.5436, -0.3807,  0.8636]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1100_loss:  0.07146219909191132  critic_loss:  4.9227305680688005e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0141],\n",
      "        [-0.0144],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4660, -0.8061,  0.9013],\n",
      "        [-0.4403, -0.8466,  0.9449],\n",
      "        [-0.5324, -0.4436,  0.7940],\n",
      "        [-0.5429, -0.3950,  0.8622]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1120_loss:  0.07145348191261292  critic_loss:  4.860568878939375e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0141],\n",
      "        [-0.0144],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4682, -0.7966,  0.9047],\n",
      "        [-0.4442, -0.8338,  0.9467],\n",
      "        [-0.5328, -0.4262,  0.7970],\n",
      "        [-0.5469, -0.3793,  0.8668]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1140_loss:  0.07144791632890701  critic_loss:  4.798960617335979e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0141],\n",
      "        [-0.0144],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4694, -0.8040,  0.9064],\n",
      "        [-0.4426, -0.8390,  0.9495],\n",
      "        [-0.5296, -0.4441,  0.7959],\n",
      "        [-0.5465, -0.4020,  0.8685]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1160_loss:  0.07147486507892609  critic_loss:  4.7375247049785685e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0157],\n",
      "        [-0.0140],\n",
      "        [-0.0143],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4663, -0.8075,  0.9032],\n",
      "        [-0.4408, -0.8393,  0.9499],\n",
      "        [-0.5291, -0.4545,  0.7905],\n",
      "        [-0.5490, -0.4161,  0.8678]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1180_loss:  0.07011771202087402  critic_loss:  6.494820354419062e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0174],\n",
      "        [-0.0157],\n",
      "        [-0.0160],\n",
      "        [-0.0180]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4621, -0.8159,  0.9178],\n",
      "        [-0.4328, -0.8484,  0.9617],\n",
      "        [-0.5218, -0.4729,  0.8217],\n",
      "        [-0.5443, -0.4365,  0.8896]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1200_loss:  0.07169432193040848  critic_loss:  4.692305083153769e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0152],\n",
      "        [-0.0135],\n",
      "        [-0.0138],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4758, -0.8023,  0.9071],\n",
      "        [-0.4498, -0.8333,  0.9536],\n",
      "        [-0.5269, -0.4309,  0.7970],\n",
      "        [-0.5497, -0.3965,  0.8752]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1220_loss:  0.07150609791278839  critic_loss:  4.580854238156462e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0141],\n",
      "        [-0.0143],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4686, -0.8037,  0.9101],\n",
      "        [-0.4460, -0.8301,  0.9553],\n",
      "        [-0.5196, -0.4233,  0.8043],\n",
      "        [-0.5424, -0.3941,  0.8810]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1240_loss:  0.07139842957258224  critic_loss:  4.5289116314961575e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0141],\n",
      "        [-0.0143],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4664, -0.8088,  0.9093],\n",
      "        [-0.4441, -0.8355,  0.9565],\n",
      "        [-0.5169, -0.4320,  0.8007],\n",
      "        [-0.5395, -0.4085,  0.8789]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1260_loss:  0.07142367213964462  critic_loss:  4.477067705010995e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0157],\n",
      "        [-0.0141],\n",
      "        [-0.0143],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4644, -0.8160,  0.9116],\n",
      "        [-0.4412, -0.8405,  0.9585],\n",
      "        [-0.5153, -0.4427,  0.8057],\n",
      "        [-0.5386, -0.4216,  0.8807]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1280_loss:  0.07143821567296982  critic_loss:  4.4284302020969335e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0157],\n",
      "        [-0.0140],\n",
      "        [-0.0142],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4640, -0.8104,  0.9142],\n",
      "        [-0.4409, -0.8337,  0.9603],\n",
      "        [-0.5138, -0.4241,  0.8109],\n",
      "        [-0.5382, -0.4043,  0.8839]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1300_loss:  0.0714307650923729  critic_loss:  4.381236067274585e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0157],\n",
      "        [-0.0140],\n",
      "        [-0.0142],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4618, -0.8148,  0.9148],\n",
      "        [-0.4366, -0.8352,  0.9614],\n",
      "        [-0.5070, -0.4256,  0.8113],\n",
      "        [-0.5344, -0.4098,  0.8842]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1320_loss:  0.0714263841509819  critic_loss:  4.335256107879104e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0157],\n",
      "        [-0.0140],\n",
      "        [-0.0142],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4635, -0.8229,  0.9176],\n",
      "        [-0.4347, -0.8386,  0.9633],\n",
      "        [-0.4995, -0.4412,  0.8211],\n",
      "        [-0.5346, -0.4256,  0.8884]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1340_loss:  0.07142142206430435  critic_loss:  4.29030569648603e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0141],\n",
      "        [-0.0142],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4597, -0.8244,  0.9202],\n",
      "        [-0.4342, -0.8370,  0.9643],\n",
      "        [-0.4951, -0.4389,  0.8242],\n",
      "        [-0.5335, -0.4254,  0.8907]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1360_loss:  0.07141497731208801  critic_loss:  4.246304797561606e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0140],\n",
      "        [-0.0142],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4594, -0.8159,  0.9229],\n",
      "        [-0.4356, -0.8285,  0.9658],\n",
      "        [-0.4919, -0.4186,  0.8294],\n",
      "        [-0.5327, -0.4027,  0.8942]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1380_loss:  0.07141086459159851  critic_loss:  4.2031192606373224e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0140],\n",
      "        [-0.0141],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4616, -0.8282,  0.9254],\n",
      "        [-0.4413, -0.8368,  0.9669],\n",
      "        [-0.4950, -0.4394,  0.8326],\n",
      "        [-0.5362, -0.4235,  0.8972]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1400_loss:  0.07107499241828918  critic_loss:  4.271567377145402e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0146],\n",
      "        [-0.0147],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4584, -0.8265,  0.9313],\n",
      "        [-0.4413, -0.8318,  0.9693],\n",
      "        [-0.4939, -0.4338,  0.8444],\n",
      "        [-0.5363, -0.4154,  0.9046]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1420_loss:  0.07161415368318558  critic_loss:  4.190787876723334e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0150],\n",
      "        [-0.0132],\n",
      "        [-0.0132],\n",
      "        [-0.0155]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4763, -0.8280,  0.9403],\n",
      "        [-0.4590, -0.8310,  0.9730],\n",
      "        [-0.5082, -0.4329,  0.8585],\n",
      "        [-0.5520, -0.4115,  0.9150]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1440_loss:  0.07160342484712601  critic_loss:  4.122021437069634e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0142],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4682, -0.8243,  0.9368],\n",
      "        [-0.4530, -0.8225,  0.9706],\n",
      "        [-0.4936, -0.4261,  0.8515],\n",
      "        [-0.5461, -0.4004,  0.9077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1460_loss:  0.07131361216306686  critic_loss:  4.066430392413167e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0142],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4633, -0.8334,  0.9400],\n",
      "        [-0.4522, -0.8280,  0.9720],\n",
      "        [-0.4944, -0.4499,  0.8539],\n",
      "        [-0.5442, -0.4161,  0.9087]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1480_loss:  0.07137429714202881  critic_loss:  4.0190147956309374e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0141],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4681, -0.8394,  0.9450],\n",
      "        [-0.4575, -0.8312,  0.9740],\n",
      "        [-0.4985, -0.4486,  0.8590],\n",
      "        [-0.5477, -0.4228,  0.9137]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1500_loss:  0.07140018790960312  critic_loss:  3.981686404586071e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4811, -0.8322,  0.9467],\n",
      "        [-0.4700, -0.8204,  0.9745],\n",
      "        [-0.5107, -0.4223,  0.8596],\n",
      "        [-0.5576, -0.3959,  0.9165]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1520_loss:  0.07141657918691635  critic_loss:  3.946439392166212e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4865, -0.8437,  0.9471],\n",
      "        [-0.4727, -0.8290,  0.9745],\n",
      "        [-0.5124, -0.4423,  0.8589],\n",
      "        [-0.5590, -0.4168,  0.9176]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1540_loss:  0.07141347974538803  critic_loss:  3.911975909431931e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4953, -0.8403,  0.9465],\n",
      "        [-0.4773, -0.8216,  0.9741],\n",
      "        [-0.5156, -0.4289,  0.8576],\n",
      "        [-0.5636, -0.4000,  0.9173]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1560_loss:  0.0714121088385582  critic_loss:  3.877910785377026e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5001, -0.8328,  0.9484],\n",
      "        [-0.4803, -0.8103,  0.9749],\n",
      "        [-0.5175, -0.4052,  0.8599],\n",
      "        [-0.5675, -0.3742,  0.9194]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1580_loss:  0.07141028344631195  critic_loss:  3.844099410343915e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5012, -0.8330,  0.9481],\n",
      "        [-0.4795, -0.8088,  0.9747],\n",
      "        [-0.5158, -0.4002,  0.8585],\n",
      "        [-0.5663, -0.3719,  0.9194]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1600_loss:  0.07141001522541046  critic_loss:  3.8104226405266672e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5057, -0.8429,  0.9494],\n",
      "        [-0.4805, -0.8178,  0.9756],\n",
      "        [-0.5164, -0.4217,  0.8599],\n",
      "        [-0.5660, -0.3966,  0.9219]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1620_loss:  0.0714096948504448  critic_loss:  3.777141728278366e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5082, -0.8439,  0.9515],\n",
      "        [-0.4768, -0.8155,  0.9767],\n",
      "        [-0.5105, -0.4189,  0.8636],\n",
      "        [-0.5632, -0.3959,  0.9247]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1640_loss:  0.07143256813287735  critic_loss:  3.7450186027854215e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5122, -0.8352,  0.9538],\n",
      "        [-0.4797, -0.8035,  0.9779],\n",
      "        [-0.5129, -0.3971,  0.8675],\n",
      "        [-0.5662, -0.3760,  0.9277]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1660_loss:  0.07049209624528885  critic_loss:  4.690973128163023e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0181],\n",
      "        [-0.0163],\n",
      "        [-0.0161],\n",
      "        [-0.0185]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.4931, -0.8552,  0.9659],\n",
      "        [-0.4519, -0.8255,  0.9842],\n",
      "        [-0.4859, -0.4424,  0.8938],\n",
      "        [-0.5463, -0.4302,  0.9431]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1680_loss:  0.07144705951213837  critic_loss:  3.698206455737818e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0155],\n",
      "        [-0.0136],\n",
      "        [-0.0134],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5189, -0.8319,  0.9626],\n",
      "        [-0.4774, -0.7946,  0.9823],\n",
      "        [-0.4951, -0.3774,  0.8871],\n",
      "        [-0.5506, -0.3552,  0.9403]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1700_loss:  0.07144159078598022  critic_loss:  3.6640362850448582e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0143],\n",
      "        [-0.0141],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5132, -0.8337,  0.9625],\n",
      "        [-0.4750, -0.7945,  0.9822],\n",
      "        [-0.4876, -0.4034,  0.8806],\n",
      "        [-0.5495, -0.3784,  0.9386]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1720_loss:  0.07135830819606781  critic_loss:  3.6382029975357e-06066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5110, -0.8283,  0.9621],\n",
      "        [-0.4753, -0.7851,  0.9822],\n",
      "        [-0.4845, -0.3914,  0.8778],\n",
      "        [-0.5459, -0.3635,  0.9381]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1740_loss:  0.07142529636621475  critic_loss:  3.6054125303053297e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0139],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5162, -0.8325,  0.9631],\n",
      "        [-0.4798, -0.7897,  0.9827],\n",
      "        [-0.4882, -0.3995,  0.8784],\n",
      "        [-0.5463, -0.3759,  0.9400]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1760_loss:  0.07142046838998795  critic_loss:  3.5771754482993856e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0139],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5166, -0.8369,  0.9638],\n",
      "        [-0.4796, -0.7927,  0.9831],\n",
      "        [-0.4891, -0.4060,  0.8792],\n",
      "        [-0.5461, -0.3881,  0.9413]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1780_loss:  0.07141304016113281  critic_loss:  3.549187340468052e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5152, -0.8279,  0.9648],\n",
      "        [-0.4785, -0.7788,  0.9837],\n",
      "        [-0.4886, -0.3786,  0.8820],\n",
      "        [-0.5449, -0.3625,  0.9428]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1800_loss:  0.07141341269016266  critic_loss:  3.5214509352954337e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0140],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5208, -0.8342,  0.9652],\n",
      "        [-0.4817, -0.7830,  0.9841],\n",
      "        [-0.4910, -0.3879,  0.8832],\n",
      "        [-0.5450, -0.3698,  0.9445]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1820_loss:  0.07141339033842087  critic_loss:  3.4940926525450777e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5227, -0.8476,  0.9654],\n",
      "        [-0.4838, -0.7969,  0.9842],\n",
      "        [-0.4923, -0.4168,  0.8823],\n",
      "        [-0.5422, -0.3975,  0.9456]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1840_loss:  0.07141194492578506  critic_loss:  3.4669944852794288e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5196, -0.8454,  0.9664],\n",
      "        [-0.4806, -0.7913,  0.9849],\n",
      "        [-0.4869, -0.4013,  0.8857],\n",
      "        [-0.5394, -0.3846,  0.9474]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1860_loss:  0.07141175121068954  critic_loss:  3.4401609809719957e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5246, -0.8419,  0.9666],\n",
      "        [-0.4832, -0.7839,  0.9852],\n",
      "        [-0.4878, -0.3906,  0.8884],\n",
      "        [-0.5429, -0.3711,  0.9481]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1880_loss:  0.07141218334436417  critic_loss:  3.413530748730409e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5183, -0.8438,  0.9672],\n",
      "        [-0.4772, -0.7813,  0.9858],\n",
      "        [-0.4811, -0.3928,  0.8916],\n",
      "        [-0.5391, -0.3732,  0.9493]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1900_loss:  0.07141457498073578  critic_loss:  3.387257947906619e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5256, -0.8486,  0.9667],\n",
      "        [-0.4834, -0.7840,  0.9858],\n",
      "        [-0.4854, -0.4072,  0.8917],\n",
      "        [-0.5437, -0.3867,  0.9493]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1920_loss:  0.07172662019729614  critic_loss:  3.458886794760474e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0155],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5312, -0.8444,  0.9673],\n",
      "        [-0.4873, -0.7764,  0.9865],\n",
      "        [-0.4886, -0.3966,  0.8954],\n",
      "        [-0.5448, -0.3722,  0.9517]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1940_loss:  0.07163592427968979  critic_loss:  3.4246120321768103e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0149],\n",
      "        [-0.0146],\n",
      "        [-0.0170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5513, -0.8443,  0.9749],\n",
      "        [-0.5077, -0.7721,  0.9899],\n",
      "        [-0.5010, -0.3857,  0.9198],\n",
      "        [-0.5526, -0.3579,  0.9643]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1960_loss:  0.07119633257389069  critic_loss:  3.380350563020329e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5341, -0.8526,  0.9714],\n",
      "        [-0.4883, -0.7839,  0.9882],\n",
      "        [-0.4793, -0.4276,  0.9075],\n",
      "        [-0.5432, -0.3995,  0.9563]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  1980_loss:  0.07157237082719803  critic_loss:  3.318494691484375e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0140],\n",
      "        [-0.0137],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5256, -0.8464,  0.9708],\n",
      "        [-0.4804, -0.7740,  0.9880],\n",
      "        [-0.4768, -0.4144,  0.9031],\n",
      "        [-0.5381, -0.3867,  0.9548]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2000_loss:  0.07143732905387878  critic_loss:  3.2749589990999084e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5287, -0.8524,  0.9721],\n",
      "        [-0.4828, -0.7809,  0.9888],\n",
      "        [-0.4801, -0.4255,  0.9076],\n",
      "        [-0.5391, -0.3999,  0.9574]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2020_loss:  0.07142294198274612  critic_loss:  3.2513189580640756e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5330, -0.8465,  0.9719],\n",
      "        [-0.4867, -0.7719,  0.9888],\n",
      "        [-0.4849, -0.4024,  0.9054],\n",
      "        [-0.5434, -0.3791,  0.9565]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2040_loss:  0.07142772525548935  critic_loss:  3.2282871416100534e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5343, -0.8493,  0.9724],\n",
      "        [-0.4866, -0.7745,  0.9891],\n",
      "        [-0.4864, -0.4140,  0.9072],\n",
      "        [-0.5467, -0.3924,  0.9574]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2060_loss:  0.07142098993062973  critic_loss:  3.205469056410948e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5359, -0.8449,  0.9723],\n",
      "        [-0.4874, -0.7678,  0.9892],\n",
      "        [-0.4874, -0.3986,  0.9068],\n",
      "        [-0.5452, -0.3743,  0.9579]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2080_loss:  0.07141835987567902  critic_loss:  3.1828265036892844e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5342, -0.8418,  0.9731],\n",
      "        [-0.4863, -0.7634,  0.9896],\n",
      "        [-0.4859, -0.3880,  0.9090],\n",
      "        [-0.5443, -0.3672,  0.9593]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2100_loss:  0.07141666114330292  critic_loss:  3.1602471608493943e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5349, -0.8477,  0.9736],\n",
      "        [-0.4863, -0.7727,  0.9899],\n",
      "        [-0.4865, -0.4069,  0.9106],\n",
      "        [-0.5448, -0.3858,  0.9603]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2120_loss:  0.07141393423080444  critic_loss:  3.137862222502008e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0139],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5374, -0.8492,  0.9732],\n",
      "        [-0.4859, -0.7749,  0.9899],\n",
      "        [-0.4838, -0.4074,  0.9095],\n",
      "        [-0.5428, -0.3888,  0.9602]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2140_loss:  0.07141411304473877  critic_loss:  3.115660547337029e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0138],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5347, -0.8432,  0.9736],\n",
      "        [-0.4839, -0.7699,  0.9900],\n",
      "        [-0.4810, -0.3990,  0.9100],\n",
      "        [-0.5417, -0.3795,  0.9606]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2160_loss:  0.07140973955392838  critic_loss:  3.0936992061469937e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0138],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5324, -0.8397,  0.9736],\n",
      "        [-0.4816, -0.7690,  0.9900],\n",
      "        [-0.4780, -0.3988,  0.9095],\n",
      "        [-0.5394, -0.3788,  0.9606]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2180_loss:  0.07091087847948074  critic_loss:  3.3274147881456884e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0149],\n",
      "        [-0.0146],\n",
      "        [-0.0170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5308, -0.8418,  0.9753],\n",
      "        [-0.4782, -0.7765,  0.9905],\n",
      "        [-0.4715, -0.4127,  0.9148],\n",
      "        [-0.5352, -0.3930,  0.9628]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2200_loss:  0.07143930345773697  critic_loss:  3.0716344099346315e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0154],\n",
      "        [-0.0137],\n",
      "        [-0.0131],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5560, -0.8394,  0.9776],\n",
      "        [-0.4994, -0.7729,  0.9917],\n",
      "        [-0.4836, -0.3986,  0.9260],\n",
      "        [-0.5434, -0.3757,  0.9687]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2220_loss:  0.0717671662569046  critic_loss:  3.157316314172931e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0140],\n",
      "        [-0.0136],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5432, -0.8407,  0.9755],\n",
      "        [-0.4890, -0.7813,  0.9907],\n",
      "        [-0.4699, -0.4231,  0.9177],\n",
      "        [-0.5379, -0.4030,  0.9637]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2240_loss:  0.07148748636245728  critic_loss:  3.022420969500672e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0138],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5321, -0.8346,  0.9742],\n",
      "        [-0.4812, -0.7779,  0.9899],\n",
      "        [-0.4635, -0.4199,  0.9111],\n",
      "        [-0.5314, -0.4014,  0.9609]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2260_loss:  0.07144809514284134  critic_loss:  2.9988666483404813e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0138],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5328, -0.8334,  0.9750],\n",
      "        [-0.4839, -0.7798,  0.9902],\n",
      "        [-0.4632, -0.4192,  0.9131],\n",
      "        [-0.5334, -0.4045,  0.9617]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2280_loss:  0.0714392364025116  critic_loss:  2.97848487207375e-06-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0137],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5339, -0.8345,  0.9758],\n",
      "        [-0.4847, -0.7848,  0.9904],\n",
      "        [-0.4617, -0.4287,  0.9147],\n",
      "        [-0.5329, -0.4128,  0.9628]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2300_loss:  0.07141759991645813  critic_loss:  2.9585453376057558e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0137],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5313, -0.8390,  0.9759],\n",
      "        [-0.4816, -0.7889,  0.9903],\n",
      "        [-0.4567, -0.4349,  0.9135],\n",
      "        [-0.5295, -0.4208,  0.9622]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2320_loss:  0.07142534852027893  critic_loss:  2.9390398594841827e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0137],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5356, -0.8340,  0.9756],\n",
      "        [-0.4830, -0.7826,  0.9900],\n",
      "        [-0.4579, -0.4207,  0.9114],\n",
      "        [-0.5287, -0.4048,  0.9618]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2340_loss:  0.07142222672700882  critic_loss:  2.9196553441579454e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0137],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5300, -0.8298,  0.9769],\n",
      "        [-0.4800, -0.7765,  0.9905],\n",
      "        [-0.4537, -0.4029,  0.9146],\n",
      "        [-0.5265, -0.3922,  0.9630]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2360_loss:  0.07142125815153122  critic_loss:  2.900392928495421e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0137],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5327, -0.8343,  0.9775],\n",
      "        [-0.4799, -0.7815,  0.9905],\n",
      "        [-0.4540, -0.4094,  0.9150],\n",
      "        [-0.5265, -0.4008,  0.9633]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2380_loss:  0.0714205652475357  critic_loss:  2.881197815440828e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0137],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5317, -0.8370,  0.9774],\n",
      "        [-0.4784, -0.7858,  0.9903],\n",
      "        [-0.4512, -0.4187,  0.9132],\n",
      "        [-0.5233, -0.4098,  0.9631]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2400_loss:  0.07141996920108795  critic_loss:  2.8620208922802703e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0137],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5295, -0.8348,  0.9779],\n",
      "        [-0.4763, -0.7833,  0.9904],\n",
      "        [-0.4504, -0.4128,  0.9136],\n",
      "        [-0.5230, -0.4043,  0.9634]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2420_loss:  0.07135707139968872  critic_loss:  2.846964889613446e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0138],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5301, -0.8318,  0.9787],\n",
      "        [-0.4760, -0.7770,  0.9907],\n",
      "        [-0.4481, -0.3934,  0.9167],\n",
      "        [-0.5207, -0.3880,  0.9647]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2440_loss:  0.07252698391675949  critic_loss:  4.013343641418032e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0147],\n",
      "        [-0.0140],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5448, -0.8502,  0.9822],\n",
      "        [-0.4895, -0.7970,  0.9925],\n",
      "        [-0.4613, -0.4257,  0.9321],\n",
      "        [-0.5293, -0.4193,  0.9717]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2460_loss:  0.07111267000436783  critic_loss:  2.9194050057412824e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0135],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5512, -0.8401,  0.9812],\n",
      "        [-0.4910, -0.7854,  0.9918],\n",
      "        [-0.4508, -0.3965,  0.9284],\n",
      "        [-0.5225, -0.3885,  0.9701]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2480_loss:  0.07150183618068695  critic_loss:  2.8051745175616816e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0143],\n",
      "        [-0.0137],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5352, -0.8536,  0.9797],\n",
      "        [-0.4755, -0.8018,  0.9910],\n",
      "        [-0.4360, -0.4290,  0.9191],\n",
      "        [-0.5099, -0.4315,  0.9656]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2500_loss:  0.07137899100780487  critic_loss:  2.7848195713886525e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0136],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5401, -0.8532,  0.9792],\n",
      "        [-0.4836, -0.8012,  0.9909],\n",
      "        [-0.4417, -0.4239,  0.9184],\n",
      "        [-0.5123, -0.4242,  0.9656]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2520_loss:  0.0714484378695488  critic_loss:  2.763364591373829e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0136],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5429, -0.8489,  0.9782],\n",
      "        [-0.4881, -0.7961,  0.9906],\n",
      "        [-0.4475, -0.4106,  0.9141],\n",
      "        [-0.5173, -0.4109,  0.9639]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2540_loss:  0.0714418888092041  critic_loss:  2.745408892224077e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0136],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5392, -0.8413,  0.9780],\n",
      "        [-0.4854, -0.7863,  0.9906],\n",
      "        [-0.4455, -0.3895,  0.9140],\n",
      "        [-0.5152, -0.3897,  0.9639]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2560_loss:  0.0714358538389206  critic_loss:  2.727729679463664e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0136],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5442, -0.8503,  0.9785],\n",
      "        [-0.4883, -0.7991,  0.9909],\n",
      "        [-0.4460, -0.4149,  0.9154],\n",
      "        [-0.5164, -0.4150,  0.9644]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2580_loss:  0.0714324489235878  critic_loss:  2.7100511488242773e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0136],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5475, -0.8467,  0.9789],\n",
      "        [-0.4917, -0.7973,  0.9910],\n",
      "        [-0.4502, -0.4124,  0.9162],\n",
      "        [-0.5191, -0.4092,  0.9651]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2600_loss:  0.07143392413854599  critic_loss:  2.692358521017013e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0136],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5491, -0.8538,  0.9789],\n",
      "        [-0.4910, -0.8085,  0.9911],\n",
      "        [-0.4473, -0.4319,  0.9167],\n",
      "        [-0.5156, -0.4263,  0.9658]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2620_loss:  0.07143443822860718  critic_loss:  2.674919869605219e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0136],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5482, -0.8419,  0.9795],\n",
      "        [-0.4892, -0.7955,  0.9913],\n",
      "        [-0.4466, -0.4018,  0.9178],\n",
      "        [-0.5156, -0.3941,  0.9666]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2640_loss:  0.0714348703622818  critic_loss:  2.657538743733312e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0142],\n",
      "        [-0.0136],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5533, -0.8514,  0.9799],\n",
      "        [-0.4907, -0.8099,  0.9914],\n",
      "        [-0.4469, -0.4305,  0.9176],\n",
      "        [-0.5139, -0.4199,  0.9671]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2660_loss:  0.07143663614988327  critic_loss:  2.6400912247481756e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0142],\n",
      "        [-0.0135],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5605, -0.8482,  0.9788],\n",
      "        [-0.4956, -0.8083,  0.9909],\n",
      "        [-0.4525, -0.4282,  0.9122],\n",
      "        [-0.5165, -0.4124,  0.9656]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2680_loss:  0.07143598794937134  critic_loss:  2.621702833494055e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0142],\n",
      "        [-0.0135],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5617, -0.8384,  0.9798],\n",
      "        [-0.4970, -0.7968,  0.9913],\n",
      "        [-0.4539, -0.3980,  0.9164],\n",
      "        [-0.5172, -0.3808,  0.9678]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2700_loss:  0.071442611515522  critic_loss:  2.602011591079645e-06-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0142],\n",
      "        [-0.0135],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5599, -0.8479,  0.9797],\n",
      "        [-0.4926, -0.8094,  0.9913],\n",
      "        [-0.4487, -0.4279,  0.9154],\n",
      "        [-0.5122, -0.4092,  0.9675]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2720_loss:  0.07202368974685669  critic_loss:  2.9268469461385394e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0150],\n",
      "        [-0.0134],\n",
      "        [-0.0127],\n",
      "        [-0.0151]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5659, -0.8404,  0.9790],\n",
      "        [-0.5002, -0.7997,  0.9910],\n",
      "        [-0.4563, -0.4061,  0.9129],\n",
      "        [-0.5187, -0.3842,  0.9667]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2740_loss:  0.0709768533706665  critic_loss:  2.7725047857529717e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0154],\n",
      "        [-0.0146],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5881, -0.8541,  0.9843],\n",
      "        [-0.5238, -0.8203,  0.9933],\n",
      "        [-0.4777, -0.4490,  0.9346],\n",
      "        [-0.5342, -0.4207,  0.9760]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2760_loss:  0.07123982906341553  critic_loss:  2.5977628865803126e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0143],\n",
      "        [-0.0136],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5775, -0.8600,  0.9818],\n",
      "        [-0.5104, -0.8268,  0.9922],\n",
      "        [-0.4569, -0.4773,  0.9242],\n",
      "        [-0.5211, -0.4564,  0.9712]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2780_loss:  0.07152833789587021  critic_loss:  2.529401399442577e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0157],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5796, -0.8506,  0.9810],\n",
      "        [-0.5147, -0.8152,  0.9916],\n",
      "        [-0.4620, -0.4614,  0.9183],\n",
      "        [-0.5231, -0.4380,  0.9685]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2800_loss:  0.07148152589797974  critic_loss:  2.5001054382300936e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0141],\n",
      "        [-0.0134],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5820, -0.8540,  0.9819],\n",
      "        [-0.5186, -0.8219,  0.9919],\n",
      "        [-0.4636, -0.4729,  0.9201],\n",
      "        [-0.5228, -0.4479,  0.9691]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2820_loss:  0.07144283503293991  critic_loss:  2.4761247914284468e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0142],\n",
      "        [-0.0134],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5879, -0.8567,  0.9828],\n",
      "        [-0.5240, -0.8262,  0.9922],\n",
      "        [-0.4699, -0.4831,  0.9240],\n",
      "        [-0.5295, -0.4564,  0.9706]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2840_loss:  0.07143627107143402  critic_loss:  2.4550736270612106e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0134],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5925, -0.8523,  0.9835],\n",
      "        [-0.5293, -0.8168,  0.9925],\n",
      "        [-0.4751, -0.4734,  0.9279],\n",
      "        [-0.5347, -0.4441,  0.9722]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2860_loss:  0.07144274562597275  critic_loss:  2.435206170048332e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0134],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.5987, -0.8537,  0.9832],\n",
      "        [-0.5347, -0.8165,  0.9924],\n",
      "        [-0.4819, -0.4813,  0.9272],\n",
      "        [-0.5398, -0.4496,  0.9721]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2880_loss:  0.071441650390625  critic_loss:  2.4164044134522555e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0134],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6071, -0.8672,  0.9835],\n",
      "        [-0.5444, -0.8336,  0.9924],\n",
      "        [-0.4899, -0.5222,  0.9290],\n",
      "        [-0.5468, -0.4898,  0.9730]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2900_loss:  0.07144152373075485  critic_loss:  2.3982286165846745e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0134],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6123, -0.8589,  0.9834],\n",
      "        [-0.5491, -0.8275,  0.9924],\n",
      "        [-0.4939, -0.5120,  0.9288],\n",
      "        [-0.5510, -0.4787,  0.9729]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2920_loss:  0.07144411653280258  critic_loss:  2.380568730586674e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0134],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6151, -0.8557,  0.9833],\n",
      "        [-0.5481, -0.8265,  0.9924],\n",
      "        [-0.4926, -0.5141,  0.9297],\n",
      "        [-0.5505, -0.4802,  0.9730]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2940_loss:  0.07144331187009811  critic_loss:  2.3633458567928756e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0134],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6134, -0.8474,  0.9829],\n",
      "        [-0.5458, -0.8161,  0.9922],\n",
      "        [-0.4897, -0.5021,  0.9281],\n",
      "        [-0.5501, -0.4646,  0.9727]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2960_loss:  0.07145299017429352  critic_loss:  2.3465454432880506e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0133],\n",
      "        [-0.0155]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6130, -0.8495,  0.9836],\n",
      "        [-0.5408, -0.8190,  0.9926],\n",
      "        [-0.4847, -0.5127,  0.9321],\n",
      "        [-0.5460, -0.4746,  0.9742]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  2980_loss:  0.07350941002368927  critic_loss:  6.584818038390949e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0138],\n",
      "        [-0.0121],\n",
      "        [-0.0113],\n",
      "        [-0.0132]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6196, -0.8442,  0.9842],\n",
      "        [-0.5499, -0.8064,  0.9929],\n",
      "        [-0.4926, -0.5006,  0.9344],\n",
      "        [-0.5541, -0.4586,  0.9754]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3000_loss:  0.07202973961830139  critic_loss:  2.66483493760461e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0155],\n",
      "        [-0.0137],\n",
      "        [-0.0129],\n",
      "        [-0.0148]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6336, -0.8525,  0.9873],\n",
      "        [-0.5666, -0.8105,  0.9944],\n",
      "        [-0.5038, -0.5067,  0.9485],\n",
      "        [-0.5643, -0.4593,  0.9813]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3020_loss:  0.07153391093015671  critic_loss:  2.317305188626051e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0143],\n",
      "        [-0.0135],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6237, -0.8652,  0.9857],\n",
      "        [-0.5569, -0.8274,  0.9935],\n",
      "        [-0.4933, -0.5459,  0.9414],\n",
      "        [-0.5541, -0.5008,  0.9782]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3040_loss:  0.07139100134372711  critic_loss:  2.297528453709674e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0143],\n",
      "        [-0.0135],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6236, -0.8652,  0.9849],\n",
      "        [-0.5550, -0.8287,  0.9930],\n",
      "        [-0.4952, -0.5553,  0.9382],\n",
      "        [-0.5557, -0.5125,  0.9764]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3060_loss:  0.07143028825521469  critic_loss:  2.2773087948735338e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0142],\n",
      "        [-0.0134],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6250, -0.8650,  0.9849],\n",
      "        [-0.5543, -0.8292,  0.9930],\n",
      "        [-0.4960, -0.5614,  0.9375],\n",
      "        [-0.5586, -0.5185,  0.9760]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3080_loss:  0.07145880907773972  critic_loss:  2.2614274257648503e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0134],\n",
      "        [-0.0155]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6293, -0.8644,  0.9852],\n",
      "        [-0.5575, -0.8280,  0.9932],\n",
      "        [-0.4980, -0.5619,  0.9390],\n",
      "        [-0.5615, -0.5191,  0.9765]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3100_loss:  0.07146529108285904  critic_loss:  2.24687369154708e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0142],\n",
      "        [-0.0134],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6306, -0.8596,  0.9860],\n",
      "        [-0.5603, -0.8240,  0.9935],\n",
      "        [-0.5000, -0.5546,  0.9421],\n",
      "        [-0.5635, -0.5099,  0.9778]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3120_loss:  0.07146093249320984  critic_loss:  2.232605993413017e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0134],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6320, -0.8667,  0.9861],\n",
      "        [-0.5603, -0.8330,  0.9936],\n",
      "        [-0.4997, -0.5790,  0.9427],\n",
      "        [-0.5634, -0.5358,  0.9781]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3140_loss:  0.07146396487951279  critic_loss:  2.2185256511875195e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0134],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6307, -0.8603,  0.9861],\n",
      "        [-0.5565, -0.8247,  0.9935],\n",
      "        [-0.4944, -0.5620,  0.9416],\n",
      "        [-0.5599, -0.5197,  0.9777]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3160_loss:  0.0714651346206665  critic_loss:  2.204594011345762e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6318, -0.8605,  0.9867],\n",
      "        [-0.5590, -0.8237,  0.9937],\n",
      "        [-0.4952, -0.5597,  0.9437],\n",
      "        [-0.5610, -0.5183,  0.9786]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3180_loss:  0.07146821171045303  critic_loss:  2.1907917471253313e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6297, -0.8702,  0.9874],\n",
      "        [-0.5556, -0.8346,  0.9941],\n",
      "        [-0.4880, -0.5783,  0.9463],\n",
      "        [-0.5558, -0.5406,  0.9796]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3200_loss:  0.07146760821342468  critic_loss:  2.177069063691306e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6345, -0.8605,  0.9873],\n",
      "        [-0.5637, -0.8225,  0.9940],\n",
      "        [-0.4988, -0.5566,  0.9459],\n",
      "        [-0.5647, -0.5171,  0.9795]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3220_loss:  0.07147965580224991  critic_loss:  2.1634757558786077e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6316, -0.8532,  0.9880],\n",
      "        [-0.5583, -0.8155,  0.9942],\n",
      "        [-0.4909, -0.5379,  0.9491],\n",
      "        [-0.5595, -0.4995,  0.9805]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3240_loss:  0.07311439514160156  critic_loss:  4.890979198535206e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0141],\n",
      "        [-0.0123],\n",
      "        [-0.0115],\n",
      "        [-0.0135]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6342, -0.8562,  0.9886],\n",
      "        [-0.5650, -0.8179,  0.9944],\n",
      "        [-0.4965, -0.5480,  0.9512],\n",
      "        [-0.5637, -0.5096,  0.9814]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3260_loss:  0.07114583253860474  critic_loss:  2.265950342916767e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0143],\n",
      "        [-0.0135],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6510, -0.8593,  0.9912],\n",
      "        [-0.5855, -0.8146,  0.9958],\n",
      "        [-0.5120, -0.5503,  0.9625],\n",
      "        [-0.5786, -0.5104,  0.9859]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3280_loss:  0.07163301855325699  critic_loss:  2.1599769297608873e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0139],\n",
      "        [-0.0131],\n",
      "        [-0.0153]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6465, -0.8603,  0.9898],\n",
      "        [-0.5738, -0.8246,  0.9951],\n",
      "        [-0.5005, -0.5651,  0.9566],\n",
      "        [-0.5689, -0.5268,  0.9834]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3300_loss:  0.07156191766262054  critic_loss:  2.123825424860115e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0140],\n",
      "        [-0.0133],\n",
      "        [-0.0155]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6405, -0.8693,  0.9894],\n",
      "        [-0.5696, -0.8397,  0.9949],\n",
      "        [-0.4966, -0.5978,  0.9542],\n",
      "        [-0.5664, -0.5635,  0.9824]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3320_loss:  0.07148907333612442  critic_loss:  2.1031455617048778e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6384, -0.8705,  0.9891],\n",
      "        [-0.5684, -0.8464,  0.9946],\n",
      "        [-0.4955, -0.6163,  0.9520],\n",
      "        [-0.5641, -0.5812,  0.9816]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3340_loss:  0.07146834582090378  critic_loss:  2.089487907142029e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6418, -0.8611,  0.9898],\n",
      "        [-0.5710, -0.8366,  0.9949],\n",
      "        [-0.4978, -0.5956,  0.9545],\n",
      "        [-0.5669, -0.5612,  0.9824]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3360_loss:  0.07148545235395432  critic_loss:  2.0756933736265637e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6416, -0.8596,  0.9901],\n",
      "        [-0.5744, -0.8329,  0.9951],\n",
      "        [-0.5010, -0.5928,  0.9552],\n",
      "        [-0.5692, -0.5579,  0.9828]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3380_loss:  0.07148021459579468  critic_loss:  2.06211780096055e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6407, -0.8642,  0.9901],\n",
      "        [-0.5717, -0.8392,  0.9951],\n",
      "        [-0.4977, -0.6043,  0.9553],\n",
      "        [-0.5674, -0.5717,  0.9827]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3400_loss:  0.07148060202598572  critic_loss:  2.048700935119996e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6375, -0.8547,  0.9909],\n",
      "        [-0.5705, -0.8291,  0.9955],\n",
      "        [-0.4946, -0.5882,  0.9582],\n",
      "        [-0.5654, -0.5551,  0.9838]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3420_loss:  0.07147971540689468  critic_loss:  2.035462330240989e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6420, -0.8626,  0.9907],\n",
      "        [-0.5772, -0.8353,  0.9953],\n",
      "        [-0.5005, -0.6032,  0.9569],\n",
      "        [-0.5708, -0.5713,  0.9833]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3440_loss:  0.0714782178401947  critic_loss:  2.0224213130859425e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6435, -0.8573,  0.9910],\n",
      "        [-0.5791, -0.8307,  0.9955],\n",
      "        [-0.5017, -0.5971,  0.9584],\n",
      "        [-0.5722, -0.5654,  0.9839]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3460_loss:  0.0714629516005516  critic_loss:  2.0098198092455277e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6365, -0.8651,  0.9913],\n",
      "        [-0.5737, -0.8395,  0.9956],\n",
      "        [-0.4950, -0.6209,  0.9592],\n",
      "        [-0.5650, -0.5906,  0.9843]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3480_loss:  0.06933438777923584  critic_loss:  6.905179361638147e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0185],\n",
      "        [-0.0166],\n",
      "        [-0.0159],\n",
      "        [-0.0185]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6443, -0.8574,  0.9920],\n",
      "        [-0.5812, -0.8310,  0.9960],\n",
      "        [-0.4989, -0.6009,  0.9623],\n",
      "        [-0.5708, -0.5731,  0.9853]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3500_loss:  0.07088528573513031  critic_loss:  2.373692041146569e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0149],\n",
      "        [-0.0141],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6482, -0.8770,  0.9934],\n",
      "        [-0.5909, -0.8474,  0.9967],\n",
      "        [-0.5072, -0.6337,  0.9687],\n",
      "        [-0.5750, -0.6056,  0.9880]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3520_loss:  0.07135214656591415  critic_loss:  2.000562972170883e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6402, -0.8719,  0.9923],\n",
      "        [-0.5817, -0.8462,  0.9960],\n",
      "        [-0.4973, -0.6214,  0.9627],\n",
      "        [-0.5663, -0.5912,  0.9856]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3540_loss:  0.07150062918663025  critic_loss:  1.9687877284013666e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6417, -0.8713,  0.9922],\n",
      "        [-0.5862, -0.8499,  0.9959],\n",
      "        [-0.5033, -0.6337,  0.9618],\n",
      "        [-0.5717, -0.6042,  0.9852]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3560_loss:  0.07147632539272308  critic_loss:  1.9561450699256966e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6447, -0.8539,  0.9921],\n",
      "        [-0.5856, -0.8328,  0.9957],\n",
      "        [-0.5021, -0.6046,  0.9602],\n",
      "        [-0.5718, -0.5736,  0.9846]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3580_loss:  0.0714748278260231  critic_loss:  1.9441533822828205e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6504, -0.8530,  0.9924],\n",
      "        [-0.5933, -0.8329,  0.9957],\n",
      "        [-0.5105, -0.6110,  0.9606],\n",
      "        [-0.5780, -0.5794,  0.9849]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3600_loss:  0.07149004936218262  critic_loss:  1.932416353156441e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6419, -0.8570,  0.9928],\n",
      "        [-0.5861, -0.8394,  0.9960],\n",
      "        [-0.5023, -0.6242,  0.9629],\n",
      "        [-0.5721, -0.5941,  0.9857]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3620_loss:  0.07148366421461105  critic_loss:  1.921023340401007e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0133],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6448, -0.8547,  0.9926],\n",
      "        [-0.5878, -0.8328,  0.9958],\n",
      "        [-0.5030, -0.6179,  0.9612],\n",
      "        [-0.5727, -0.5875,  0.9850]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3640_loss:  0.0714845061302185  critic_loss:  1.9098231405223487e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6461, -0.8590,  0.9928],\n",
      "        [-0.5884, -0.8400,  0.9960],\n",
      "        [-0.5049, -0.6342,  0.9623],\n",
      "        [-0.5752, -0.6044,  0.9854]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3660_loss:  0.07148423045873642  critic_loss:  1.898719915516267e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6478, -0.8565,  0.9928],\n",
      "        [-0.5904, -0.8358,  0.9959],\n",
      "        [-0.5070, -0.6326,  0.9622],\n",
      "        [-0.5782, -0.6050,  0.9853]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3680_loss:  0.0714874193072319  critic_loss:  1.887744247142109e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6523, -0.8639,  0.9932],\n",
      "        [-0.5930, -0.8419,  0.9962],\n",
      "        [-0.5092, -0.6473,  0.9643],\n",
      "        [-0.5823, -0.6220,  0.9859]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3700_loss:  0.07148667424917221  critic_loss:  1.876873170658655e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6515, -0.8494,  0.9935],\n",
      "        [-0.5937, -0.8290,  0.9963],\n",
      "        [-0.5100, -0.6259,  0.9655],\n",
      "        [-0.5810, -0.5970,  0.9866]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3720_loss:  0.07160968333482742  critic_loss:  1.8818714124790858e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0138],\n",
      "        [-0.0131],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6516, -0.8572,  0.9935],\n",
      "        [-0.5894, -0.8369,  0.9964],\n",
      "        [-0.5055, -0.6464,  0.9661],\n",
      "        [-0.5800, -0.6210,  0.9865]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3740_loss:  0.07084401696920395  critic_loss:  2.311689058842603e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0141],\n",
      "        [-0.0133],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6636, -0.8550,  0.9949],\n",
      "        [-0.6086, -0.8328,  0.9972],\n",
      "        [-0.5248, -0.6388,  0.9732],\n",
      "        [-0.5952, -0.6078,  0.9896]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3760_loss:  0.07188087701797485  critic_loss:  2.0110328478040174e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0138],\n",
      "        [-0.0130],\n",
      "        [-0.0153]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6666, -0.8540,  0.9947],\n",
      "        [-0.6023, -0.8316,  0.9971],\n",
      "        [-0.5147, -0.6349,  0.9728],\n",
      "        [-0.5895, -0.6071,  0.9892]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3780_loss:  0.07159353047609329  critic_loss:  1.8541176132202963e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0140],\n",
      "        [-0.0133],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6538, -0.8525,  0.9940],\n",
      "        [-0.5928, -0.8405,  0.9965],\n",
      "        [-0.5085, -0.6483,  0.9688],\n",
      "        [-0.5816, -0.6182,  0.9877]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3800_loss:  0.07151240855455399  critic_loss:  1.8320323533771443e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6587, -0.8492,  0.9940],\n",
      "        [-0.5940, -0.8405,  0.9965],\n",
      "        [-0.5113, -0.6447,  0.9684],\n",
      "        [-0.5849, -0.6152,  0.9874]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3820_loss:  0.07151379436254501  critic_loss:  1.8213661405752646e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6568, -0.8486,  0.9943],\n",
      "        [-0.5924, -0.8425,  0.9967],\n",
      "        [-0.5103, -0.6497,  0.9700],\n",
      "        [-0.5842, -0.6201,  0.9880]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3840_loss:  0.07150176167488098  critic_loss:  1.8108294170815498e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6645, -0.8525,  0.9944],\n",
      "        [-0.5991, -0.8461,  0.9968],\n",
      "        [-0.5169, -0.6570,  0.9712],\n",
      "        [-0.5927, -0.6298,  0.9883]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3860_loss:  0.07149382680654526  critic_loss:  1.8007303879130632e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6623, -0.8383,  0.9945],\n",
      "        [-0.5959, -0.8350,  0.9967],\n",
      "        [-0.5144, -0.6383,  0.9713],\n",
      "        [-0.5902, -0.6085,  0.9883]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3880_loss:  0.0714946836233139  critic_loss:  1.7907825622387463e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6733, -0.8475,  0.9946],\n",
      "        [-0.6020, -0.8449,  0.9968],\n",
      "        [-0.5222, -0.6527,  0.9720],\n",
      "        [-0.5989, -0.6244,  0.9886]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3900_loss:  0.07149465382099152  critic_loss:  1.7809618384490022e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6768, -0.8553,  0.9947],\n",
      "        [-0.6063, -0.8533,  0.9968],\n",
      "        [-0.5260, -0.6704,  0.9724],\n",
      "        [-0.6009, -0.6409,  0.9888]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3920_loss:  0.07149376720190048  critic_loss:  1.7712202406983124e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6655, -0.8451,  0.9948],\n",
      "        [-0.5938, -0.8430,  0.9969],\n",
      "        [-0.5127, -0.6515,  0.9737],\n",
      "        [-0.5921, -0.6234,  0.9891]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3940_loss:  0.07149412482976913  critic_loss:  1.7615649312574533e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6693, -0.8460,  0.9947],\n",
      "        [-0.5975, -0.8439,  0.9969],\n",
      "        [-0.5163, -0.6514,  0.9736],\n",
      "        [-0.5960, -0.6235,  0.9891]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3960_loss:  0.07149380445480347  critic_loss:  1.7519378161523491e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6777, -0.8461,  0.9948],\n",
      "        [-0.6037, -0.8448,  0.9969],\n",
      "        [-0.5219, -0.6547,  0.9740],\n",
      "        [-0.6015, -0.6274,  0.9892]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  3980_loss:  0.07158089429140091  critic_loss:  1.7505209370938246e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0138],\n",
      "        [-0.0131],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6764, -0.8515,  0.9950],\n",
      "        [-0.6021, -0.8529,  0.9971],\n",
      "        [-0.5195, -0.6686,  0.9752],\n",
      "        [-0.6001, -0.6423,  0.9897]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4000_loss:  0.07026346772909164  critic_loss:  3.372193987161154e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0148],\n",
      "        [-0.0140],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6951, -0.8477,  0.9959],\n",
      "        [-0.6214, -0.8503,  0.9977],\n",
      "        [-0.5369, -0.6578,  0.9802],\n",
      "        [-0.6170, -0.6327,  0.9918]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4020_loss:  0.07193553447723389  critic_loss:  1.9334963781147962e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0138],\n",
      "        [-0.0130],\n",
      "        [-0.0154]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7017, -0.8403,  0.9957],\n",
      "        [-0.6201, -0.8476,  0.9976],\n",
      "        [-0.5341, -0.6561,  0.9797],\n",
      "        [-0.6181, -0.6345,  0.9914]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4040_loss:  0.07147472351789474  critic_loss:  1.7251757071790053e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0141],\n",
      "        [-0.0134],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6889, -0.8352,  0.9953],\n",
      "        [-0.6050, -0.8525,  0.9973],\n",
      "        [-0.5215, -0.6645,  0.9772],\n",
      "        [-0.6054, -0.6413,  0.9904]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4060_loss:  0.07144246250391006  critic_loss:  1.7175173070427263e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0140],\n",
      "        [-0.0133],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6947, -0.8239,  0.9951],\n",
      "        [-0.6040, -0.8428,  0.9971],\n",
      "        [-0.5212, -0.6497,  0.9758],\n",
      "        [-0.6053, -0.6254,  0.9899]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4080_loss:  0.07148008793592453  critic_loss:  1.7041849105225992e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6966, -0.8273,  0.9952],\n",
      "        [-0.6053, -0.8460,  0.9972],\n",
      "        [-0.5222, -0.6535,  0.9765],\n",
      "        [-0.6081, -0.6314,  0.9901]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4100_loss:  0.07149633020162582  critic_loss:  1.6943317859841045e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.6962, -0.8384,  0.9952],\n",
      "        [-0.6004, -0.8571,  0.9972],\n",
      "        [-0.5188, -0.6739,  0.9770],\n",
      "        [-0.6060, -0.6533,  0.9902]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4120_loss:  0.07150382548570633  critic_loss:  1.6852702628966654e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0140],\n",
      "        [-0.0132],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7073, -0.8316,  0.9952],\n",
      "        [-0.6079, -0.8526,  0.9972],\n",
      "        [-0.5270, -0.6660,  0.9771],\n",
      "        [-0.6137, -0.6443,  0.9902]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4140_loss:  0.07149843126535416  critic_loss:  1.676401211625489e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7031, -0.8324,  0.9954],\n",
      "        [-0.6011, -0.8557,  0.9974],\n",
      "        [-0.5202, -0.6700,  0.9784],\n",
      "        [-0.6092, -0.6495,  0.9907]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4160_loss:  0.0714990496635437  critic_loss:  1.66767449627514e-06-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7067, -0.8247,  0.9953],\n",
      "        [-0.5990, -0.8503,  0.9974],\n",
      "        [-0.5181, -0.6629,  0.9783],\n",
      "        [-0.6089, -0.6427,  0.9905]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4180_loss:  0.07149814814329147  critic_loss:  1.659013150856481e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7034, -0.8308,  0.9955],\n",
      "        [-0.5972, -0.8560,  0.9975],\n",
      "        [-0.5164, -0.6712,  0.9795],\n",
      "        [-0.6085, -0.6539,  0.9911]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4200_loss:  0.07149628549814224  critic_loss:  1.6503372535225935e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7082, -0.8299,  0.9956],\n",
      "        [-0.5970, -0.8575,  0.9976],\n",
      "        [-0.5164, -0.6705,  0.9801],\n",
      "        [-0.6080, -0.6526,  0.9913]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4220_loss:  0.071493960916996  critic_loss:  1.6417064898632816e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7202, -0.8147,  0.9957],\n",
      "        [-0.6055, -0.8472,  0.9977],\n",
      "        [-0.5247, -0.6514,  0.9811],\n",
      "        [-0.6156, -0.6320,  0.9919]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4240_loss:  0.07149207592010498  critic_loss:  1.6331223378074355e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7158, -0.8209,  0.9959],\n",
      "        [-0.6010, -0.8564,  0.9978],\n",
      "        [-0.5197, -0.6688,  0.9816],\n",
      "        [-0.6105, -0.6485,  0.9921]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4260_loss:  0.07143210619688034  critic_loss:  1.6283021295748767e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0140],\n",
      "        [-0.0133],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7151, -0.8172,  0.9962],\n",
      "        [-0.6010, -0.8569,  0.9980],\n",
      "        [-0.5162, -0.6647,  0.9831],\n",
      "        [-0.6071, -0.6448,  0.9928]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4280_loss:  0.07320021092891693  critic_loss:  4.594488018483389e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0156],\n",
      "        [-0.0132],\n",
      "        [-0.0124],\n",
      "        [-0.0148]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7392, -0.8097,  0.9968],\n",
      "        [-0.6279, -0.8556,  0.9983],\n",
      "        [-0.5412, -0.6464,  0.9858],\n",
      "        [-0.6346, -0.6322,  0.9940]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4300_loss:  0.07096927613019943  critic_loss:  1.930064854605007e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0171],\n",
      "        [-0.0146],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7394, -0.8355,  0.9972],\n",
      "        [-0.6292, -0.8796,  0.9985],\n",
      "        [-0.5400, -0.6971,  0.9878],\n",
      "        [-0.6350, -0.6867,  0.9948]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4320_loss:  0.07169879227876663  critic_loss:  1.6527098978258437e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0138],\n",
      "        [-0.0131],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7290, -0.8154,  0.9968],\n",
      "        [-0.6101, -0.8724,  0.9982],\n",
      "        [-0.5275, -0.6812,  0.9856],\n",
      "        [-0.6229, -0.6666,  0.9940]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4340_loss:  0.07146184146404266  critic_loss:  1.603594910193351e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0140],\n",
      "        [-0.0133],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7236, -0.8223,  0.9966],\n",
      "        [-0.6058, -0.8816,  0.9981],\n",
      "        [-0.5267, -0.6938,  0.9844],\n",
      "        [-0.6158, -0.6776,  0.9935]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4360_loss:  0.0714825913310051  critic_loss:  1.5927264485071646e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7265, -0.8123,  0.9966],\n",
      "        [-0.6046, -0.8751,  0.9980],\n",
      "        [-0.5289, -0.6834,  0.9842],\n",
      "        [-0.6188, -0.6635,  0.9934]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4380_loss:  0.0714958906173706  critic_loss:  1.583568291607662e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7350, -0.8177,  0.9967],\n",
      "        [-0.6146, -0.8789,  0.9981],\n",
      "        [-0.5366, -0.6894,  0.9845],\n",
      "        [-0.6264, -0.6704,  0.9936]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4400_loss:  0.07149626314640045  critic_loss:  1.575241867612931e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7386, -0.8137,  0.9968],\n",
      "        [-0.6158, -0.8797,  0.9981],\n",
      "        [-0.5373, -0.6868,  0.9850],\n",
      "        [-0.6277, -0.6659,  0.9937]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4420_loss:  0.07149779051542282  critic_loss:  1.567146910019801e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7279, -0.8260,  0.9969],\n",
      "        [-0.6055, -0.8898,  0.9982],\n",
      "        [-0.5242, -0.6995,  0.9858],\n",
      "        [-0.6129, -0.6809,  0.9941]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4440_loss:  0.07149772346019745  critic_loss:  1.5592233921779552e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7369, -0.8332,  0.9970],\n",
      "        [-0.6154, -0.8961,  0.9982],\n",
      "        [-0.5353, -0.7122,  0.9860],\n",
      "        [-0.6231, -0.6938,  0.9942]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4460_loss:  0.07149562984704971  critic_loss:  1.5514195865762304e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7330, -0.8186,  0.9971],\n",
      "        [-0.6071, -0.8887,  0.9983],\n",
      "        [-0.5279, -0.6898,  0.9866],\n",
      "        [-0.6164, -0.6698,  0.9944]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4480_loss:  0.07149621099233627  critic_loss:  1.5437113916050293e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0139],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7452, -0.8238,  0.9971],\n",
      "        [-0.6199, -0.8932,  0.9983],\n",
      "        [-0.5391, -0.6972,  0.9867],\n",
      "        [-0.6292, -0.6779,  0.9944]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4500_loss:  0.07149524241685867  critic_loss:  1.5360531051555881e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7452, -0.8131,  0.9973],\n",
      "        [-0.6149, -0.8858,  0.9984],\n",
      "        [-0.5332, -0.6812,  0.9875],\n",
      "        [-0.6274, -0.6582,  0.9948]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4520_loss:  0.07149477303028107  critic_loss:  1.528470761513745e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7497, -0.8055,  0.9972],\n",
      "        [-0.6189, -0.8811,  0.9984],\n",
      "        [-0.5389, -0.6727,  0.9869],\n",
      "        [-0.6333, -0.6478,  0.9945]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4540_loss:  0.07149331271648407  critic_loss:  1.5209337789201527e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7512, -0.8097,  0.9974],\n",
      "        [-0.6197, -0.8853,  0.9985],\n",
      "        [-0.5394, -0.6827,  0.9879],\n",
      "        [-0.6338, -0.6574,  0.9950]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4560_loss:  0.07147642225027084  critic_loss:  1.5137983382373932e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7532, -0.8069,  0.9974],\n",
      "        [-0.6224, -0.8834,  0.9985],\n",
      "        [-0.5395, -0.6775,  0.9878],\n",
      "        [-0.6314, -0.6512,  0.9949]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4580_loss:  0.06931353360414505  critic_loss:  6.819233931310009e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0183],\n",
      "        [-0.0159],\n",
      "        [-0.0153],\n",
      "        [-0.0181]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7492, -0.8061,  0.9980],\n",
      "        [-0.6164, -0.8850,  0.9989],\n",
      "        [-0.5292, -0.6718,  0.9903],\n",
      "        [-0.6225, -0.6473,  0.9960]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4600_loss:  0.0716419667005539  critic_loss:  1.5358076552729472e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0136],\n",
      "        [-0.0129],\n",
      "        [-0.0154]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7790, -0.8024,  0.9982],\n",
      "        [-0.6487, -0.8863,  0.9990],\n",
      "        [-0.5570, -0.6772,  0.9912],\n",
      "        [-0.6605, -0.6566,  0.9964]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4620_loss:  0.07150272279977798  critic_loss:  1.5040753851280897e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0141],\n",
      "        [-0.0134],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7695, -0.7939,  0.9981],\n",
      "        [-0.6275, -0.8883,  0.9989],\n",
      "        [-0.5405, -0.6831,  0.9905],\n",
      "        [-0.6486, -0.6608,  0.9961]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4640_loss:  0.07144583761692047  critic_loss:  1.4987051599746337e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0139],\n",
      "        [-0.0133],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7602, -0.8122,  0.9979],\n",
      "        [-0.6170, -0.9008,  0.9988],\n",
      "        [-0.5314, -0.7104,  0.9897],\n",
      "        [-0.6327, -0.6877,  0.9957]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4660_loss:  0.07151953130960464  critic_loss:  1.4848332057226798e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7596, -0.7933,  0.9978],\n",
      "        [-0.6171, -0.8900,  0.9987],\n",
      "        [-0.5345, -0.6862,  0.9891],\n",
      "        [-0.6326, -0.6613,  0.9955]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4680_loss:  0.07151427865028381  critic_loss:  1.4769033214179217e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7660, -0.8087,  0.9980],\n",
      "        [-0.6266, -0.8976,  0.9988],\n",
      "        [-0.5429, -0.7063,  0.9900],\n",
      "        [-0.6394, -0.6815,  0.9959]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4700_loss:  0.07150562852621078  critic_loss:  1.4693654293296277e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7617, -0.7883,  0.9979],\n",
      "        [-0.6196, -0.8877,  0.9988],\n",
      "        [-0.5366, -0.6844,  0.9896],\n",
      "        [-0.6314, -0.6593,  0.9957]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4720_loss:  0.0715055912733078  critic_loss:  1.4620792399000493e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7653, -0.7880,  0.9979],\n",
      "        [-0.6218, -0.8873,  0.9988],\n",
      "        [-0.5376, -0.6840,  0.9894],\n",
      "        [-0.6341, -0.6601,  0.9956]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4740_loss:  0.0715053603053093  critic_loss:  1.4549309526046272e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7649, -0.7895,  0.9980],\n",
      "        [-0.6198, -0.8892,  0.9988],\n",
      "        [-0.5372, -0.6909,  0.9899],\n",
      "        [-0.6314, -0.6662,  0.9958]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4760_loss:  0.07150541990995407  critic_loss:  1.4478843013421283e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7757, -0.7739,  0.9981],\n",
      "        [-0.6303, -0.8839,  0.9989],\n",
      "        [-0.5452, -0.6771,  0.9902],\n",
      "        [-0.6417, -0.6521,  0.9960]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4780_loss:  0.07150401920080185  critic_loss:  1.4409025652639684e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0138],\n",
      "        [-0.0132],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7747, -0.7851,  0.9982],\n",
      "        [-0.6285, -0.8928,  0.9989],\n",
      "        [-0.5427, -0.6964,  0.9905],\n",
      "        [-0.6397, -0.6725,  0.9961]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4800_loss:  0.07150564342737198  critic_loss:  1.4339705103338929e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0138],\n",
      "        [-0.0133],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7826, -0.7640,  0.9982],\n",
      "        [-0.6381, -0.8816,  0.9989],\n",
      "        [-0.5518, -0.6761,  0.9903],\n",
      "        [-0.6494, -0.6520,  0.9960]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4820_loss:  0.07150661200284958  critic_loss:  1.427094957762165e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0137],\n",
      "        [-0.0133],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7780, -0.7760,  0.9983],\n",
      "        [-0.6341, -0.8909,  0.9989],\n",
      "        [-0.5467, -0.6951,  0.9909],\n",
      "        [-0.6411, -0.6740,  0.9963]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4840_loss:  0.07150572538375854  critic_loss:  1.4202684042174951e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0137],\n",
      "        [-0.0133],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7743, -0.7655,  0.9984],\n",
      "        [-0.6288, -0.8864,  0.9990],\n",
      "        [-0.5410, -0.6840,  0.9912],\n",
      "        [-0.6333, -0.6634,  0.9964]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4860_loss:  0.07155133038759232  critic_loss:  1.4157847090245923e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0137],\n",
      "        [-0.0132],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7822, -0.7634,  0.9983],\n",
      "        [-0.6351, -0.8859,  0.9990],\n",
      "        [-0.5468, -0.6812,  0.9908],\n",
      "        [-0.6441, -0.6606,  0.9963]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4880_loss:  0.07004296779632568  critic_loss:  3.797441195274587e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0184],\n",
      "        [-0.0158],\n",
      "        [-0.0155],\n",
      "        [-0.0182]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7774, -0.7593,  0.9988],\n",
      "        [-0.6328, -0.8858,  0.9993],\n",
      "        [-0.5399, -0.6727,  0.9935],\n",
      "        [-0.6341, -0.6554,  0.9974]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4900_loss:  0.0718817412853241  critic_loss:  1.555274820930208e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0135],\n",
      "        [-0.0129],\n",
      "        [-0.0154]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7969, -0.7454,  0.9988],\n",
      "        [-0.6546, -0.8737,  0.9993],\n",
      "        [-0.5564, -0.6433,  0.9934],\n",
      "        [-0.6589, -0.6374,  0.9972]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4920_loss:  0.07134958356618881  critic_loss:  1.438426693312067e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0141],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7879, -0.7592,  0.9987],\n",
      "        [-0.6417, -0.8846,  0.9992],\n",
      "        [-0.5516, -0.6823,  0.9924],\n",
      "        [-0.6483, -0.6656,  0.9969]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4940_loss:  0.07155784964561462  critic_loss:  1.3976884929434163e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0138],\n",
      "        [-0.0133],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7823, -0.7803,  0.9986],\n",
      "        [-0.6374, -0.8968,  0.9991],\n",
      "        [-0.5559, -0.7141,  0.9919],\n",
      "        [-0.6453, -0.6947,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4960_loss:  0.0715484619140625  critic_loss:  1.3889406318412512e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0138],\n",
      "        [-0.0133],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7873, -0.7854,  0.9985],\n",
      "        [-0.6444, -0.9005,  0.9991],\n",
      "        [-0.5596, -0.7210,  0.9919],\n",
      "        [-0.6501, -0.7013,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  4980_loss:  0.07152462005615234  critic_loss:  1.3809350321025704e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0138],\n",
      "        [-0.0133],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7803, -0.7542,  0.9985],\n",
      "        [-0.6382, -0.8844,  0.9991],\n",
      "        [-0.5541, -0.6811,  0.9917],\n",
      "        [-0.6388, -0.6591,  0.9966]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5000_loss:  0.0715208426117897  critic_loss:  1.3738819006903213e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0137],\n",
      "        [-0.0133],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7858, -0.7437,  0.9985],\n",
      "        [-0.6449, -0.8807,  0.9991],\n",
      "        [-0.5599, -0.6733,  0.9918],\n",
      "        [-0.6468, -0.6506,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5020_loss:  0.07151889055967331  critic_loss:  1.367088998449617e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0137],\n",
      "        [-0.0133],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7825, -0.7563,  0.9985],\n",
      "        [-0.6399, -0.8874,  0.9991],\n",
      "        [-0.5556, -0.6864,  0.9916],\n",
      "        [-0.6410, -0.6645,  0.9966]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5040_loss:  0.07151617854833603  critic_loss:  1.360483906864829e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7858, -0.7355,  0.9986],\n",
      "        [-0.6488, -0.8764,  0.9991],\n",
      "        [-0.5629, -0.6616,  0.9920],\n",
      "        [-0.6456, -0.6432,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5060_loss:  0.07151516526937485  critic_loss:  1.3539965948439203e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7862, -0.7374,  0.9986],\n",
      "        [-0.6483, -0.8780,  0.9991],\n",
      "        [-0.5648, -0.6654,  0.9921],\n",
      "        [-0.6474, -0.6482,  0.9968]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5080_loss:  0.07151485979557037  critic_loss:  1.3475815876518027e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7872, -0.7335,  0.9986],\n",
      "        [-0.6508, -0.8759,  0.9991],\n",
      "        [-0.5669, -0.6592,  0.9923],\n",
      "        [-0.6493, -0.6476,  0.9968]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5100_loss:  0.07151395827531815  critic_loss:  1.3412216048891423e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7902, -0.7581,  0.9986],\n",
      "        [-0.6562, -0.8890,  0.9991],\n",
      "        [-0.5717, -0.6867,  0.9923],\n",
      "        [-0.6522, -0.6777,  0.9968]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5120_loss:  0.07151466608047485  critic_loss:  1.334932676400058e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7821, -0.7543,  0.9987],\n",
      "        [-0.6473, -0.8865,  0.9992],\n",
      "        [-0.5625, -0.6774,  0.9930],\n",
      "        [-0.6435, -0.6715,  0.9970]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5140_loss:  0.07151582837104797  critic_loss:  1.3286908142617904e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7787, -0.7473,  0.9986],\n",
      "        [-0.6416, -0.8817,  0.9991],\n",
      "        [-0.5564, -0.6711,  0.9927],\n",
      "        [-0.6377, -0.6647,  0.9969]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5160_loss:  0.07151725143194199  critic_loss:  1.3224940857980982e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0136],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7865, -0.7592,  0.9987],\n",
      "        [-0.6526, -0.8870,  0.9992],\n",
      "        [-0.5669, -0.6794,  0.9932],\n",
      "        [-0.6473, -0.6746,  0.9972]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5180_loss:  0.07182987779378891  critic_loss:  1.4205152183421887e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0159],\n",
      "        [-0.0132],\n",
      "        [-0.0129],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7894, -0.7382,  0.9987],\n",
      "        [-0.6547, -0.8712,  0.9992],\n",
      "        [-0.5680, -0.6511,  0.9931],\n",
      "        [-0.6480, -0.6456,  0.9971]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5200_loss:  0.071975938975811  critic_loss:  1.565515844959009e-06-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0174],\n",
      "        [-0.0147],\n",
      "        [-0.0143],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8098, -0.7580,  0.9991],\n",
      "        [-0.6846, -0.8712,  0.9995],\n",
      "        [-0.5870, -0.6423,  0.9954],\n",
      "        [-0.6695, -0.6430,  0.9981]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5220_loss:  0.07164622098207474  critic_loss:  1.3388176967055188e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0136],\n",
      "        [-0.0132],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8097, -0.7791,  0.9990],\n",
      "        [-0.6791, -0.8812,  0.9994],\n",
      "        [-0.5809, -0.6613,  0.9951],\n",
      "        [-0.6635, -0.6631,  0.9979]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5240_loss:  0.07143574953079224  critic_loss:  1.3208519931140472e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0140],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7938, -0.7926,  0.9990],\n",
      "        [-0.6614, -0.8964,  0.9994],\n",
      "        [-0.5709, -0.7018,  0.9947],\n",
      "        [-0.6491, -0.6930,  0.9978]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5260_loss:  0.07154890149831772  critic_loss:  1.3012958106628503e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0138],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7906, -0.7729,  0.9989],\n",
      "        [-0.6562, -0.8889,  0.9993],\n",
      "        [-0.5699, -0.6874,  0.9942],\n",
      "        [-0.6454, -0.6751,  0.9976]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5280_loss:  0.0715554878115654  critic_loss:  1.2941223985762917e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0138],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7895, -0.7659,  0.9989],\n",
      "        [-0.6573, -0.8871,  0.9993],\n",
      "        [-0.5743, -0.6819,  0.9941],\n",
      "        [-0.6479, -0.6695,  0.9976]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5300_loss:  0.07153727859258652  critic_loss:  1.2870777936768718e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7880, -0.7605,  0.9988],\n",
      "        [-0.6529, -0.8839,  0.9993],\n",
      "        [-0.5658, -0.6702,  0.9940],\n",
      "        [-0.6412, -0.6592,  0.9976]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5320_loss:  0.0715341866016388  critic_loss:  1.2806666518372367e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7920, -0.7590,  0.9989],\n",
      "        [-0.6576, -0.8835,  0.9993],\n",
      "        [-0.5751, -0.6718,  0.9943],\n",
      "        [-0.6479, -0.6597,  0.9977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5340_loss:  0.07153065502643585  critic_loss:  1.2744698096867069e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7911, -0.7468,  0.9989],\n",
      "        [-0.6539, -0.8772,  0.9993],\n",
      "        [-0.5710, -0.6576,  0.9943],\n",
      "        [-0.6446, -0.6454,  0.9977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5360_loss:  0.0715285912156105  critic_loss:  1.268427354261803e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7965, -0.7511,  0.9989],\n",
      "        [-0.6610, -0.8782,  0.9994],\n",
      "        [-0.5790, -0.6594,  0.9945],\n",
      "        [-0.6511, -0.6496,  0.9977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5380_loss:  0.07152806967496872  critic_loss:  1.2624774399228045e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7881, -0.7516,  0.9989],\n",
      "        [-0.6482, -0.8741,  0.9994],\n",
      "        [-0.5646, -0.6494,  0.9947],\n",
      "        [-0.6404, -0.6421,  0.9978]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5400_loss:  0.07152685523033142  critic_loss:  1.2565935776365222e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7917, -0.7622,  0.9990],\n",
      "        [-0.6571, -0.8798,  0.9995],\n",
      "        [-0.5741, -0.6673,  0.9951],\n",
      "        [-0.6477, -0.6617,  0.9980]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5420_loss:  0.07152727246284485  critic_loss:  1.2507763358371449e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7920, -0.7796,  0.9990],\n",
      "        [-0.6580, -0.8875,  0.9994],\n",
      "        [-0.5772, -0.6857,  0.9949],\n",
      "        [-0.6490, -0.6768,  0.9979]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5440_loss:  0.07153016328811646  critic_loss:  1.2450136637198739e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7928, -0.7640,  0.9990],\n",
      "        [-0.6562, -0.8796,  0.9994],\n",
      "        [-0.5763, -0.6657,  0.9950],\n",
      "        [-0.6482, -0.6589,  0.9979]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5460_loss:  0.0715273767709732  critic_loss:  1.2392906683089677e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7899, -0.7650,  0.9990],\n",
      "        [-0.6531, -0.8765,  0.9995],\n",
      "        [-0.5714, -0.6594,  0.9950],\n",
      "        [-0.6441, -0.6514,  0.9979]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5480_loss:  0.07153063267469406  critic_loss:  1.2335985957179219e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0137],\n",
      "        [-0.0134],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7917, -0.7546,  0.9990],\n",
      "        [-0.6556, -0.8671,  0.9995],\n",
      "        [-0.5734, -0.6375,  0.9953],\n",
      "        [-0.6459, -0.6300,  0.9980]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5500_loss:  0.07183389365673065  critic_loss:  1.3264079825603403e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0133],\n",
      "        [-0.0130],\n",
      "        [-0.0157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7904, -0.7637,  0.9990],\n",
      "        [-0.6528, -0.8701,  0.9995],\n",
      "        [-0.5705, -0.6429,  0.9954],\n",
      "        [-0.6421, -0.6341,  0.9981]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5520_loss:  0.07228691130876541  critic_loss:  1.8593990489534917e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0171],\n",
      "        [-0.0143],\n",
      "        [-0.0140],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8112, -0.7688,  0.9993],\n",
      "        [-0.6849, -0.8693,  0.9997],\n",
      "        [-0.5916, -0.6312,  0.9968],\n",
      "        [-0.6633, -0.6265,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5540_loss:  0.07140572369098663  critic_loss:  1.252706738341658e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0138],\n",
      "        [-0.0134],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8179, -0.7981,  0.9992],\n",
      "        [-0.6832, -0.8835,  0.9997],\n",
      "        [-0.5900, -0.6630,  0.9967],\n",
      "        [-0.6633, -0.6604,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5560_loss:  0.07157903164625168  critic_loss:  1.2234932000865228e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8020, -0.7760,  0.9992],\n",
      "        [-0.6667, -0.8785,  0.9996],\n",
      "        [-0.5835, -0.6548,  0.9963],\n",
      "        [-0.6510, -0.6398,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5580_loss:  0.0715010017156601  critic_loss:  1.2165644420747412e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0138],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8052, -0.7750,  0.9991],\n",
      "        [-0.6682, -0.8763,  0.9996],\n",
      "        [-0.5885, -0.6504,  0.9961],\n",
      "        [-0.6536, -0.6339,  0.9984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5600_loss:  0.07155009359121323  critic_loss:  1.2074472124368185e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0138],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8017, -0.7866,  0.9991],\n",
      "        [-0.6631, -0.8816,  0.9996],\n",
      "        [-0.5874, -0.6607,  0.9961],\n",
      "        [-0.6522, -0.6443,  0.9984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5620_loss:  0.0715474784374237  critic_loss:  1.2012010301987175e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0138],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8077, -0.7930,  0.9991],\n",
      "        [-0.6685, -0.8854,  0.9996],\n",
      "        [-0.5929, -0.6711,  0.9961],\n",
      "        [-0.6566, -0.6555,  0.9984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5640_loss:  0.07154323160648346  critic_loss:  1.195254412778013e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7996, -0.7787,  0.9991],\n",
      "        [-0.6576, -0.8786,  0.9996],\n",
      "        [-0.5826, -0.6498,  0.9961],\n",
      "        [-0.6466, -0.6311,  0.9984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5660_loss:  0.07153990119695663  critic_loss:  1.1895093621205888e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8066, -0.7739,  0.9992],\n",
      "        [-0.6656, -0.8745,  0.9996],\n",
      "        [-0.5892, -0.6432,  0.9963],\n",
      "        [-0.6536, -0.6244,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5680_loss:  0.07154110819101334  critic_loss:  1.1838782256745617e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8093, -0.7870,  0.9992],\n",
      "        [-0.6707, -0.8840,  0.9996],\n",
      "        [-0.5965, -0.6668,  0.9964],\n",
      "        [-0.6585, -0.6460,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5700_loss:  0.07154230028390884  critic_loss:  1.1783193940573256e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8076, -0.7565,  0.9992],\n",
      "        [-0.6666, -0.8662,  0.9997],\n",
      "        [-0.5912, -0.6274,  0.9964],\n",
      "        [-0.6537, -0.6023,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5720_loss:  0.07154082506895065  critic_loss:  1.1728404842870077e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8036, -0.7776,  0.9992],\n",
      "        [-0.6663, -0.8781,  0.9996],\n",
      "        [-0.5878, -0.6552,  0.9963],\n",
      "        [-0.6517, -0.6313,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5740_loss:  0.0715399980545044  critic_loss:  1.1674267170747044e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8019, -0.7620,  0.9992],\n",
      "        [-0.6631, -0.8700,  0.9997],\n",
      "        [-0.5861, -0.6360,  0.9966],\n",
      "        [-0.6501, -0.6102,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5760_loss:  0.0715419128537178  critic_loss:  1.1620622899499722e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7965, -0.7764,  0.9992],\n",
      "        [-0.6584, -0.8789,  0.9997],\n",
      "        [-0.5841, -0.6590,  0.9964],\n",
      "        [-0.6469, -0.6323,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5780_loss:  0.07154190540313721  critic_loss:  1.1567368574105785e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8123, -0.7580,  0.9992],\n",
      "        [-0.6751, -0.8708,  0.9997],\n",
      "        [-0.5970, -0.6379,  0.9965],\n",
      "        [-0.6575, -0.6076,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5800_loss:  0.07152464985847473  critic_loss:  1.1519671261339681e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8014, -0.7396,  0.9993],\n",
      "        [-0.6632, -0.8590,  0.9997],\n",
      "        [-0.5847, -0.6119,  0.9967],\n",
      "        [-0.6490, -0.5813,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5820_loss:  0.07011169195175171  critic_loss:  3.5868467875843635e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0176],\n",
      "        [-0.0147],\n",
      "        [-0.0144],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7936, -0.7582,  0.9994],\n",
      "        [-0.6534, -0.8716,  0.9998],\n",
      "        [-0.5757, -0.6343,  0.9972],\n",
      "        [-0.6443, -0.6075,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5840_loss:  0.07221448421478271  critic_loss:  1.608602133273962e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0138],\n",
      "        [-0.0134],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8344, -0.7716,  0.9995],\n",
      "        [-0.7076, -0.8702,  0.9998],\n",
      "        [-0.6110, -0.6290,  0.9976],\n",
      "        [-0.6771, -0.6058,  0.9991]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5860_loss:  0.07138992846012115  critic_loss:  1.1794264764830587e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0136],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8168, -0.7679,  0.9994],\n",
      "        [-0.6827, -0.8750,  0.9998],\n",
      "        [-0.5960, -0.6460,  0.9972],\n",
      "        [-0.6615, -0.6149,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5880_loss:  0.07163052260875702  critic_loss:  1.1458213293735753e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0138],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8070, -0.7685,  0.9993],\n",
      "        [-0.6700, -0.8783,  0.9997],\n",
      "        [-0.5859, -0.6527,  0.9969],\n",
      "        [-0.6507, -0.6202,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5900_loss:  0.07153704762458801  critic_loss:  1.1339433285684208e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0138],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8082, -0.7610,  0.9993],\n",
      "        [-0.6743, -0.8742,  0.9997],\n",
      "        [-0.5904, -0.6422,  0.9968],\n",
      "        [-0.6527, -0.6076,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5920_loss:  0.07154662907123566  critic_loss:  1.1272597930656048e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0138],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8033, -0.7596,  0.9993],\n",
      "        [-0.6683, -0.8694,  0.9997],\n",
      "        [-0.5849, -0.6350,  0.9968],\n",
      "        [-0.6494, -0.6016,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5940_loss:  0.07155152410268784  critic_loss:  1.1213930974918185e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0138],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8062, -0.7480,  0.9993],\n",
      "        [-0.6685, -0.8624,  0.9997],\n",
      "        [-0.5839, -0.6148,  0.9967],\n",
      "        [-0.6498, -0.5825,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5960_loss:  0.07155308872461319  critic_loss:  1.1158593906657188e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0138],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.7980, -0.7742,  0.9993],\n",
      "        [-0.6560, -0.8783,  0.9998],\n",
      "        [-0.5753, -0.6514,  0.9970],\n",
      "        [-0.6426, -0.6212,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  5980_loss:  0.07155333459377289  critic_loss:  1.1105036037406535e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8058, -0.7705,  0.9993],\n",
      "        [-0.6673, -0.8734,  0.9998],\n",
      "        [-0.5842, -0.6349,  0.9968],\n",
      "        [-0.6507, -0.6038,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6000_loss:  0.07155157625675201  critic_loss:  1.1052526360799675e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0137],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8123, -0.7637,  0.9993],\n",
      "        [-0.6712, -0.8710,  0.9998],\n",
      "        [-0.5877, -0.6330,  0.9970],\n",
      "        [-0.6532, -0.6001,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6020_loss:  0.0715520977973938  critic_loss:  1.1000967106156168e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0137],\n",
      "        [-0.0136],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8008, -0.7522,  0.9993],\n",
      "        [-0.6594, -0.8647,  0.9998],\n",
      "        [-0.5765, -0.6175,  0.9968],\n",
      "        [-0.6431, -0.5823,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6040_loss:  0.07155393809080124  critic_loss:  1.0950066098303068e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0137],\n",
      "        [-0.0136],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8028, -0.7655,  0.9993],\n",
      "        [-0.6621, -0.8741,  0.9998],\n",
      "        [-0.5784, -0.6312,  0.9968],\n",
      "        [-0.6429, -0.5941,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6060_loss:  0.0715561956167221  critic_loss:  1.0899664175667567e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0137],\n",
      "        [-0.0136],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8029, -0.7612,  0.9993],\n",
      "        [-0.6628, -0.8711,  0.9998],\n",
      "        [-0.5787, -0.6271,  0.9968],\n",
      "        [-0.6443, -0.5894,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6080_loss:  0.07155417650938034  critic_loss:  1.0849594218598213e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0136],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8076, -0.7573,  0.9992],\n",
      "        [-0.6656, -0.8683,  0.9998],\n",
      "        [-0.5826, -0.6194,  0.9967],\n",
      "        [-0.6469, -0.5802,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6100_loss:  0.0715603157877922  critic_loss:  1.0800166592161986e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0136],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8138, -0.7486,  0.9993],\n",
      "        [-0.6683, -0.8665,  0.9998],\n",
      "        [-0.5830, -0.6133,  0.9968],\n",
      "        [-0.6471, -0.5732,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6120_loss:  0.07234601676464081  critic_loss:  1.73957903371047e-0666\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0158],\n",
      "        [-0.0127],\n",
      "        [-0.0126],\n",
      "        [-0.0151]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8162, -0.7532,  0.9992],\n",
      "        [-0.6676, -0.8678,  0.9998],\n",
      "        [-0.5827, -0.6176,  0.9967],\n",
      "        [-0.6468, -0.5782,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6140_loss:  0.07072757184505463  critic_loss:  1.8332519857722218e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0178],\n",
      "        [-0.0149],\n",
      "        [-0.0147],\n",
      "        [-0.0172]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8335, -0.7501,  0.9995],\n",
      "        [-0.6876, -0.8590,  0.9999],\n",
      "        [-0.5915, -0.5835,  0.9978],\n",
      "        [-0.6620, -0.5476,  0.9992]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6160_loss:  0.07177500426769257  critic_loss:  1.1266045021329774e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0137],\n",
      "        [-0.0133],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8226, -0.7940,  0.9994],\n",
      "        [-0.6737, -0.8838,  0.9998],\n",
      "        [-0.5828, -0.6420,  0.9974],\n",
      "        [-0.6495, -0.6076,  0.9990]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6180_loss:  0.07160704582929611  critic_loss:  1.070475036613061e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0139],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8221, -0.7907,  0.9994],\n",
      "        [-0.6733, -0.8860,  0.9998],\n",
      "        [-0.5872, -0.6500,  0.9972],\n",
      "        [-0.6480, -0.6112,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6200_loss:  0.07154370099306107  critic_loss:  1.06296943158668e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8192, -0.7657,  0.9993],\n",
      "        [-0.6686, -0.8746,  0.9998],\n",
      "        [-0.5842, -0.6241,  0.9969],\n",
      "        [-0.6411, -0.5805,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6220_loss:  0.07155941426753998  critic_loss:  1.0565730690359487e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8129, -0.7650,  0.9993],\n",
      "        [-0.6606, -0.8722,  0.9998],\n",
      "        [-0.5800, -0.6210,  0.9969],\n",
      "        [-0.6372, -0.5769,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6240_loss:  0.07156812399625778  critic_loss:  1.0511486152608995e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0136],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8166, -0.7730,  0.9993],\n",
      "        [-0.6630, -0.8744,  0.9998],\n",
      "        [-0.5824, -0.6245,  0.9969],\n",
      "        [-0.6414, -0.5806,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6260_loss:  0.07156474888324738  critic_loss:  1.0459882560098777e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0136],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8186, -0.7702,  0.9993],\n",
      "        [-0.6640, -0.8723,  0.9998],\n",
      "        [-0.5860, -0.6216,  0.9967],\n",
      "        [-0.6435, -0.5785,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6280_loss:  0.07156489789485931  critic_loss:  1.0409844435343985e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8199, -0.7912,  0.9993],\n",
      "        [-0.6645, -0.8812,  0.9998],\n",
      "        [-0.5865, -0.6414,  0.9967],\n",
      "        [-0.6425, -0.5979,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6300_loss:  0.07156401127576828  critic_loss:  1.0360499800299294e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8171, -0.7843,  0.9993],\n",
      "        [-0.6591, -0.8751,  0.9998],\n",
      "        [-0.5808, -0.6266,  0.9970],\n",
      "        [-0.6393, -0.5826,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6320_loss:  0.07156269252300262  critic_loss:  1.03117042726808e-0606\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8187, -0.7646,  0.9993],\n",
      "        [-0.6599, -0.8653,  0.9998],\n",
      "        [-0.5811, -0.6065,  0.9968],\n",
      "        [-0.6374, -0.5583,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6340_loss:  0.07156354188919067  critic_loss:  1.0263503327223589e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8206, -0.7835,  0.9992],\n",
      "        [-0.6587, -0.8752,  0.9998],\n",
      "        [-0.5839, -0.6280,  0.9967],\n",
      "        [-0.6374, -0.5800,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6360_loss:  0.07156353443861008  critic_loss:  1.0215990187134594e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8303, -0.7787,  0.9992],\n",
      "        [-0.6733, -0.8741,  0.9998],\n",
      "        [-0.5961, -0.6267,  0.9967],\n",
      "        [-0.6487, -0.5790,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6380_loss:  0.07156756520271301  critic_loss:  1.0168917015107581e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8192, -0.7778,  0.9993],\n",
      "        [-0.6546, -0.8708,  0.9998],\n",
      "        [-0.5779, -0.6116,  0.9969],\n",
      "        [-0.6350, -0.5658,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6400_loss:  0.07208110392093658  critic_loss:  1.2954076282767346e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0130],\n",
      "        [-0.0130],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8278, -0.7645,  0.9992],\n",
      "        [-0.6655, -0.8617,  0.9998],\n",
      "        [-0.5909, -0.5929,  0.9966],\n",
      "        [-0.6440, -0.5421,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6420_loss:  0.07062476873397827  critic_loss:  1.9838412299577612e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0181],\n",
      "        [-0.0151],\n",
      "        [-0.0150],\n",
      "        [-0.0175]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8401, -0.7759,  0.9995],\n",
      "        [-0.6904, -0.8630,  0.9999],\n",
      "        [-0.5999, -0.5726,  0.9981],\n",
      "        [-0.6581, -0.5266,  0.9993]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6440_loss:  0.07186268270015717  critic_loss:  1.110524181058281e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0140],\n",
      "        [-0.0137],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8397, -0.7953,  0.9994],\n",
      "        [-0.6844, -0.8782,  0.9999],\n",
      "        [-0.5975, -0.6105,  0.9978],\n",
      "        [-0.6495, -0.5616,  0.9992]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6460_loss:  0.07156483083963394  critic_loss:  1.0114317774423398e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0138],\n",
      "        [-0.0135],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8369, -0.7982,  0.9993],\n",
      "        [-0.6779, -0.8824,  0.9998],\n",
      "        [-0.5996, -0.6251,  0.9972],\n",
      "        [-0.6457, -0.5743,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6480_loss:  0.07161247730255127  critic_loss:  1.0036623052656068e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8265, -0.7939,  0.9993],\n",
      "        [-0.6706, -0.8777,  0.9998],\n",
      "        [-0.5972, -0.6149,  0.9971],\n",
      "        [-0.6436, -0.5635,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6500_loss:  0.07157275825738907  critic_loss:  9.970264045477961e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8218, -0.7879,  0.9992],\n",
      "        [-0.6644, -0.8741,  0.9998],\n",
      "        [-0.5912, -0.6101,  0.9968],\n",
      "        [-0.6366, -0.5559,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6520_loss:  0.07158161699771881  critic_loss:  9.912376981446869e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0136],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8314, -0.7675,  0.9992],\n",
      "        [-0.6775, -0.8628,  0.9998],\n",
      "        [-0.6038, -0.5900,  0.9967],\n",
      "        [-0.6469, -0.5318,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6540_loss:  0.07158337533473969  critic_loss:  9.86044256023888e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8322, -0.7929,  0.9992],\n",
      "        [-0.6766, -0.8778,  0.9998],\n",
      "        [-0.6013, -0.6183,  0.9965],\n",
      "        [-0.6457, -0.5649,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6560_loss:  0.07158512622117996  critic_loss:  9.811282097871299e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8297, -0.7682,  0.9992],\n",
      "        [-0.6704, -0.8616,  0.9998],\n",
      "        [-0.5962, -0.5833,  0.9964],\n",
      "        [-0.6395, -0.5241,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6580_loss:  0.07158442586660385  critic_loss:  9.763579100763309e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8350, -0.7808,  0.9992],\n",
      "        [-0.6762, -0.8712,  0.9998],\n",
      "        [-0.5994, -0.6007,  0.9966],\n",
      "        [-0.6457, -0.5486,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6600_loss:  0.07158347964286804  critic_loss:  9.717003877085517e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8350, -0.7962,  0.9992],\n",
      "        [-0.6795, -0.8793,  0.9998],\n",
      "        [-0.6046, -0.6227,  0.9966],\n",
      "        [-0.6495, -0.5727,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6620_loss:  0.07158312201499939  critic_loss:  9.671225598140154e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0138],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8363, -0.8055,  0.9992],\n",
      "        [-0.6759, -0.8859,  0.9998],\n",
      "        [-0.6002, -0.6306,  0.9964],\n",
      "        [-0.6454, -0.5841,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6640_loss:  0.07158312201499939  critic_loss:  9.625960046832915e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0138],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8360, -0.7891,  0.9992],\n",
      "        [-0.6823, -0.8749,  0.9998],\n",
      "        [-0.6058, -0.6173,  0.9963],\n",
      "        [-0.6520, -0.5692,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6660_loss:  0.07158340513706207  critic_loss:  9.581104905009852e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8325, -0.7889,  0.9992],\n",
      "        [-0.6793, -0.8764,  0.9998],\n",
      "        [-0.6016, -0.6195,  0.9963],\n",
      "        [-0.6467, -0.5699,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6680_loss:  0.0715840682387352  critic_loss:  9.536550464872562e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8365, -0.7736,  0.9992],\n",
      "        [-0.6783, -0.8652,  0.9998],\n",
      "        [-0.5983, -0.5928,  0.9966],\n",
      "        [-0.6449, -0.5395,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6700_loss:  0.07158365845680237  critic_loss:  9.492255230725277e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8406, -0.7687,  0.9991],\n",
      "        [-0.6833, -0.8595,  0.9998],\n",
      "        [-0.6060, -0.5822,  0.9962],\n",
      "        [-0.6506, -0.5270,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6720_loss:  0.07169582694768906  critic_loss:  9.583608289176482e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0136],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8505, -0.7795,  0.9991],\n",
      "        [-0.6972, -0.8684,  0.9998],\n",
      "        [-0.6177, -0.5998,  0.9960],\n",
      "        [-0.6617, -0.5474,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6740_loss:  0.07258298993110657  critic_loss:  2.0915831555612385e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0157],\n",
      "        [-0.0126],\n",
      "        [-0.0123],\n",
      "        [-0.0146]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8399, -0.7301,  0.9993],\n",
      "        [-0.6965, -0.8247,  0.9998],\n",
      "        [-0.6105, -0.5075,  0.9971],\n",
      "        [-0.6549, -0.4488,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6760_loss:  0.07125061005353928  critic_loss:  1.0777719126053853e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0140],\n",
      "        [-0.0137],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8611, -0.8066,  0.9995],\n",
      "        [-0.7111, -0.8783,  0.9999],\n",
      "        [-0.6244, -0.6146,  0.9978],\n",
      "        [-0.6699, -0.5708,  0.9992]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6780_loss:  0.07143747806549072  critic_loss:  9.70735641203646e-0776\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0171],\n",
      "        [-0.0140],\n",
      "        [-0.0138],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8498, -0.8188,  0.9993],\n",
      "        [-0.6982, -0.8877,  0.9998],\n",
      "        [-0.6189, -0.6459,  0.9971],\n",
      "        [-0.6607, -0.5964,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6800_loss:  0.0716499537229538  critic_loss:  9.426739779883064e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0136],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8516, -0.8087,  0.9992],\n",
      "        [-0.7005, -0.8788,  0.9998],\n",
      "        [-0.6269, -0.6289,  0.9967],\n",
      "        [-0.6654, -0.5735,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6820_loss:  0.07156742364168167  critic_loss:  9.323728704657697e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8434, -0.7903,  0.9992],\n",
      "        [-0.6895, -0.8668,  0.9998],\n",
      "        [-0.6172, -0.6116,  0.9963],\n",
      "        [-0.6564, -0.5549,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6840_loss:  0.07158713787794113  critic_loss:  9.26329903450096e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8419, -0.8004,  0.9991],\n",
      "        [-0.6881, -0.8730,  0.9998],\n",
      "        [-0.6117, -0.6216,  0.9962],\n",
      "        [-0.6545, -0.5690,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6860_loss:  0.07158802449703217  critic_loss:  9.213077873937436e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8530, -0.7819,  0.9991],\n",
      "        [-0.6933, -0.8627,  0.9998],\n",
      "        [-0.6186, -0.5961,  0.9960],\n",
      "        [-0.6620, -0.5404,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6880_loss:  0.07158651202917099  critic_loss:  9.165603387373267e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8497, -0.8030,  0.9991],\n",
      "        [-0.6902, -0.8748,  0.9998],\n",
      "        [-0.6125, -0.6159,  0.9961],\n",
      "        [-0.6586, -0.5637,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6900_loss:  0.07158482074737549  critic_loss:  9.1200348606435e-0707\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8540, -0.8084,  0.9991],\n",
      "        [-0.6930, -0.8799,  0.9998],\n",
      "        [-0.6165, -0.6314,  0.9960],\n",
      "        [-0.6637, -0.5791,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6920_loss:  0.07158508896827698  critic_loss:  9.075849334294617e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8598, -0.8044,  0.9990],\n",
      "        [-0.6966, -0.8770,  0.9997],\n",
      "        [-0.6192, -0.6145,  0.9957],\n",
      "        [-0.6671, -0.5602,  0.9984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6940_loss:  0.0715840607881546  critic_loss:  9.032438583744806e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8654, -0.7773,  0.9991],\n",
      "        [-0.6989, -0.8594,  0.9998],\n",
      "        [-0.6251, -0.5883,  0.9959],\n",
      "        [-0.6727, -0.5258,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6960_loss:  0.07158458232879639  critic_loss:  8.9895365817938e-0707\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8618, -0.7967,  0.9990],\n",
      "        [-0.6918, -0.8714,  0.9997],\n",
      "        [-0.6163, -0.6042,  0.9956],\n",
      "        [-0.6647, -0.5444,  0.9984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  6980_loss:  0.07158485054969788  critic_loss:  8.947005767367955e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8616, -0.7942,  0.9990],\n",
      "        [-0.6902, -0.8700,  0.9997],\n",
      "        [-0.6157, -0.6078,  0.9954],\n",
      "        [-0.6637, -0.5481,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7000_loss:  0.07158573716878891  critic_loss:  8.904794412956107e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8621, -0.7677,  0.9990],\n",
      "        [-0.6909, -0.8508,  0.9997],\n",
      "        [-0.6173, -0.5680,  0.9955],\n",
      "        [-0.6675, -0.5054,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7020_loss:  0.07158553600311279  critic_loss:  8.862947993293346e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8686, -0.7693,  0.9990],\n",
      "        [-0.6971, -0.8536,  0.9997],\n",
      "        [-0.6250, -0.5763,  0.9954],\n",
      "        [-0.6755, -0.5104,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7040_loss:  0.07158278673887253  critic_loss:  8.821390906632587e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8692, -0.8018,  0.9990],\n",
      "        [-0.6967, -0.8762,  0.9997],\n",
      "        [-0.6222, -0.6163,  0.9956],\n",
      "        [-0.6751, -0.5553,  0.9984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7060_loss:  0.07124117016792297  critic_loss:  1.0056270411951118e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0174],\n",
      "        [-0.0143],\n",
      "        [-0.0144],\n",
      "        [-0.0171]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8702, -0.7877,  0.9990],\n",
      "        [-0.6968, -0.8648,  0.9997],\n",
      "        [-0.6198, -0.5916,  0.9954],\n",
      "        [-0.6730, -0.5282,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7080_loss:  0.07102812826633453  critic_loss:  1.2208450925754732e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0171],\n",
      "        [-0.0139],\n",
      "        [-0.0138],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8761, -0.7830,  0.9993],\n",
      "        [-0.7115, -0.8546,  0.9998],\n",
      "        [-0.6304, -0.5851,  0.9968],\n",
      "        [-0.6769, -0.5139,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7100_loss:  0.07170658558607101  critic_loss:  9.06139518974669e-0706\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0172],\n",
      "        [-0.0140],\n",
      "        [-0.0139],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8844, -0.8249,  0.9992],\n",
      "        [-0.7171, -0.8856,  0.9998],\n",
      "        [-0.6392, -0.6481,  0.9966],\n",
      "        [-0.6869, -0.5767,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7120_loss:  0.07151453197002411  critic_loss:  8.823637358545966e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8784, -0.8201,  0.9991],\n",
      "        [-0.7033, -0.8819,  0.9998],\n",
      "        [-0.6321, -0.6350,  0.9961],\n",
      "        [-0.6814, -0.5674,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7140_loss:  0.07163313031196594  critic_loss:  8.713057582099282e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8750, -0.8275,  0.9990],\n",
      "        [-0.7047, -0.8879,  0.9997],\n",
      "        [-0.6352, -0.6489,  0.9958],\n",
      "        [-0.6859, -0.5824,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7160_loss:  0.07160814851522446  critic_loss:  8.642159627925139e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8759, -0.8161,  0.9990],\n",
      "        [-0.7026, -0.8812,  0.9998],\n",
      "        [-0.6310, -0.6329,  0.9959],\n",
      "        [-0.6860, -0.5605,  0.9985]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7180_loss:  0.07159516960382462  critic_loss:  8.591489404352615e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8780, -0.7885,  0.9989],\n",
      "        [-0.7008, -0.8625,  0.9997],\n",
      "        [-0.6340, -0.6013,  0.9952],\n",
      "        [-0.6907, -0.5243,  0.9982]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7200_loss:  0.07158974558115005  critic_loss:  8.546210210624849e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8781, -0.7995,  0.9989],\n",
      "        [-0.7002, -0.8693,  0.9997],\n",
      "        [-0.6324, -0.6106,  0.9953],\n",
      "        [-0.6906, -0.5351,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7220_loss:  0.07159042358398438  critic_loss:  8.503123467562546e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8816, -0.8215,  0.9989],\n",
      "        [-0.7034, -0.8842,  0.9997],\n",
      "        [-0.6339, -0.6327,  0.9953],\n",
      "        [-0.6960, -0.5616,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7240_loss:  0.07158995419740677  critic_loss:  8.461281595373293e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8869, -0.8066,  0.9990],\n",
      "        [-0.7108, -0.8737,  0.9997],\n",
      "        [-0.6387, -0.6183,  0.9954],\n",
      "        [-0.7024, -0.5433,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7260_loss:  0.07158935815095901  critic_loss:  8.420152539656556e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8909, -0.8079,  0.9988],\n",
      "        [-0.7148, -0.8740,  0.9997],\n",
      "        [-0.6447, -0.6201,  0.9949],\n",
      "        [-0.7076, -0.5450,  0.9981]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7280_loss:  0.07158941775560379  critic_loss:  8.379533369407e-07-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8870, -0.7945,  0.9988],\n",
      "        [-0.7071, -0.8647,  0.9997],\n",
      "        [-0.6339, -0.6014,  0.9946],\n",
      "        [-0.6989, -0.5249,  0.9981]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7300_loss:  0.07158945500850677  critic_loss:  8.339260944012494e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8909, -0.7965,  0.9988],\n",
      "        [-0.7117, -0.8658,  0.9997],\n",
      "        [-0.6361, -0.5962,  0.9948],\n",
      "        [-0.7029, -0.5201,  0.9981]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7320_loss:  0.0715891644358635  critic_loss:  8.299278420054179e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8905, -0.8129,  0.9988],\n",
      "        [-0.7093, -0.8760,  0.9997],\n",
      "        [-0.6313, -0.6156,  0.9948],\n",
      "        [-0.6996, -0.5389,  0.9981]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7340_loss:  0.07161299139261246  critic_loss:  8.265531050710706e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8927, -0.8160,  0.9988],\n",
      "        [-0.7128, -0.8772,  0.9997],\n",
      "        [-0.6384, -0.6218,  0.9948],\n",
      "        [-0.7049, -0.5456,  0.9981]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7360_loss:  0.07265453785657883  critic_loss:  1.9198505469830707e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0176],\n",
      "        [-0.0145],\n",
      "        [-0.0145],\n",
      "        [-0.0170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8909, -0.8002,  0.9990],\n",
      "        [-0.7125, -0.8622,  0.9998],\n",
      "        [-0.6322, -0.5842,  0.9956],\n",
      "        [-0.6987, -0.5055,  0.9984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7380_loss:  0.07116063684225082  critic_loss:  1.0449706451254315e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0172],\n",
      "        [-0.0139],\n",
      "        [-0.0139],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9033, -0.8290,  0.9992],\n",
      "        [-0.7363, -0.8751,  0.9998],\n",
      "        [-0.6575, -0.6427,  0.9968],\n",
      "        [-0.7101, -0.5478,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7400_loss:  0.07153905183076859  critic_loss:  8.316978892253246e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0171],\n",
      "        [-0.0139],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9023, -0.8366,  0.9990],\n",
      "        [-0.7335, -0.8859,  0.9998],\n",
      "        [-0.6564, -0.6601,  0.9959],\n",
      "        [-0.7099, -0.5715,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7420_loss:  0.07160127907991409  critic_loss:  8.205242352232744e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8993, -0.8212,  0.9989],\n",
      "        [-0.7242, -0.8737,  0.9997],\n",
      "        [-0.6539, -0.6325,  0.9953],\n",
      "        [-0.7120, -0.5451,  0.9984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7440_loss:  0.07162115722894669  critic_loss:  8.148215897563205e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9024, -0.8402,  0.9988],\n",
      "        [-0.7261, -0.8874,  0.9997],\n",
      "        [-0.6573, -0.6534,  0.9949],\n",
      "        [-0.7151, -0.5703,  0.9982]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7460_loss:  0.0716000348329544  critic_loss:  8.090169671959302e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9024, -0.8313,  0.9988],\n",
      "        [-0.7261, -0.8801,  0.9997],\n",
      "        [-0.6565, -0.6411,  0.9947],\n",
      "        [-0.7155, -0.5552,  0.9981]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7480_loss:  0.07160429656505585  critic_loss:  8.044583523769688e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9008, -0.8301,  0.9987],\n",
      "        [-0.7219, -0.8782,  0.9997],\n",
      "        [-0.6523, -0.6386,  0.9946],\n",
      "        [-0.7127, -0.5521,  0.9981]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7500_loss:  0.07160546630620956  critic_loss:  8.001775313459802e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.8996, -0.8119,  0.9987],\n",
      "        [-0.7190, -0.8647,  0.9997],\n",
      "        [-0.6478, -0.6040,  0.9945],\n",
      "        [-0.7086, -0.5143,  0.9981]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7520_loss:  0.07160414010286331  critic_loss:  7.960657057992648e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9066, -0.8187,  0.9987],\n",
      "        [-0.7278, -0.8712,  0.9997],\n",
      "        [-0.6606, -0.6250,  0.9943],\n",
      "        [-0.7210, -0.5350,  0.9980]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7540_loss:  0.07160436362028122  critic_loss:  7.920695566099312e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9073, -0.8343,  0.9986],\n",
      "        [-0.7288, -0.8827,  0.9996],\n",
      "        [-0.6597, -0.6451,  0.9940],\n",
      "        [-0.7192, -0.5583,  0.9979]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7560_loss:  0.07160576432943344  critic_loss:  7.88146735430928e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9088, -0.8219,  0.9986],\n",
      "        [-0.7288, -0.8729,  0.9996],\n",
      "        [-0.6596, -0.6277,  0.9940],\n",
      "        [-0.7197, -0.5378,  0.9979]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7580_loss:  0.07160508632659912  critic_loss:  7.842801892365969e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9104, -0.8167,  0.9985],\n",
      "        [-0.7312, -0.8680,  0.9996],\n",
      "        [-0.6632, -0.6205,  0.9935],\n",
      "        [-0.7231, -0.5286,  0.9977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7600_loss:  0.0716065913438797  critic_loss:  7.80458947247098e-0707\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9138, -0.8190,  0.9985],\n",
      "        [-0.7321, -0.8694,  0.9996],\n",
      "        [-0.6624, -0.6245,  0.9936],\n",
      "        [-0.7234, -0.5323,  0.9978]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7620_loss:  0.0716068372130394  critic_loss:  7.766769840600318e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9140, -0.8200,  0.9984],\n",
      "        [-0.7324, -0.8708,  0.9996],\n",
      "        [-0.6603, -0.6226,  0.9933],\n",
      "        [-0.7211, -0.5296,  0.9977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7640_loss:  0.07160136848688126  critic_loss:  7.729723847660352e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9105, -0.8160,  0.9984],\n",
      "        [-0.7287, -0.8694,  0.9996],\n",
      "        [-0.6545, -0.6251,  0.9930],\n",
      "        [-0.7158, -0.5325,  0.9975]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7660_loss:  0.07012780755758286  critic_loss:  3.157398396069766e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0191],\n",
      "        [-0.0158],\n",
      "        [-0.0162],\n",
      "        [-0.0189]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9101, -0.8267,  0.9986],\n",
      "        [-0.7293, -0.8745,  0.9996],\n",
      "        [-0.6543, -0.6287,  0.9937],\n",
      "        [-0.7158, -0.5374,  0.9978]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7680_loss:  0.07109673321247101  critic_loss:  1.0761131079561892e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0179],\n",
      "        [-0.0146],\n",
      "        [-0.0147],\n",
      "        [-0.0172]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9188, -0.8225,  0.9991],\n",
      "        [-0.7528, -0.8657,  0.9998],\n",
      "        [-0.6704, -0.6315,  0.9962],\n",
      "        [-0.7239, -0.5220,  0.9987]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7700_loss:  0.07187218964099884  critic_loss:  8.570147542741324e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0136],\n",
      "        [-0.0136],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9205, -0.8371,  0.9988],\n",
      "        [-0.7469, -0.8854,  0.9997],\n",
      "        [-0.6691, -0.6713,  0.9951],\n",
      "        [-0.7290, -0.5612,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7720_loss:  0.07151468098163605  critic_loss:  7.776137067594391e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0139],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9197, -0.8346,  0.9986],\n",
      "        [-0.7436, -0.8828,  0.9997],\n",
      "        [-0.6697, -0.6548,  0.9942],\n",
      "        [-0.7372, -0.5513,  0.9980]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7740_loss:  0.07160557061433792  critic_loss:  7.61985404551524e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0138],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9197, -0.8158,  0.9985],\n",
      "        [-0.7425, -0.8693,  0.9996],\n",
      "        [-0.6730, -0.6258,  0.9936],\n",
      "        [-0.7403, -0.5177,  0.9978]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7760_loss:  0.07162117213010788  critic_loss:  7.569890954073344e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9180, -0.8207,  0.9984],\n",
      "        [-0.7389, -0.8735,  0.9996],\n",
      "        [-0.6725, -0.6434,  0.9929],\n",
      "        [-0.7340, -0.5373,  0.9976]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7780_loss:  0.07161533087491989  critic_loss:  7.526791705458891e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9230, -0.8315,  0.9983],\n",
      "        [-0.7492, -0.8825,  0.9996],\n",
      "        [-0.6826, -0.6643,  0.9925],\n",
      "        [-0.7474, -0.5592,  0.9974]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7800_loss:  0.07161428779363632  critic_loss:  7.486797812816803e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9205, -0.8330,  0.9983],\n",
      "        [-0.7427, -0.8839,  0.9996],\n",
      "        [-0.6742, -0.6560,  0.9929],\n",
      "        [-0.7386, -0.5487,  0.9975]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7820_loss:  0.07161659002304077  critic_loss:  7.448302881130076e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9238, -0.8062,  0.9983],\n",
      "        [-0.7448, -0.8670,  0.9996],\n",
      "        [-0.6733, -0.6234,  0.9925],\n",
      "        [-0.7427, -0.5074,  0.9975]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7840_loss:  0.0716162845492363  critic_loss:  7.410847047140123e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9305, -0.7989,  0.9982],\n",
      "        [-0.7598, -0.8633,  0.9995],\n",
      "        [-0.6827, -0.6204,  0.9922],\n",
      "        [-0.7589, -0.5010,  0.9973]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7860_loss:  0.07161702960729599  critic_loss:  7.374184178843279e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9306, -0.7857,  0.9981],\n",
      "        [-0.7603, -0.8554,  0.9995],\n",
      "        [-0.6828, -0.6063,  0.9917],\n",
      "        [-0.7601, -0.4837,  0.9972]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7880_loss:  0.07161718606948853  critic_loss:  7.338096565945307e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9316, -0.7959,  0.9982],\n",
      "        [-0.7613, -0.8634,  0.9995],\n",
      "        [-0.6840, -0.6227,  0.9919],\n",
      "        [-0.7600, -0.5003,  0.9973]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7900_loss:  0.07161837071180344  critic_loss:  7.302560334210284e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9281, -0.8102,  0.9982],\n",
      "        [-0.7504, -0.8721,  0.9995],\n",
      "        [-0.6782, -0.6408,  0.9919],\n",
      "        [-0.7501, -0.5220,  0.9973]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7920_loss:  0.07161889970302582  critic_loss:  7.267388468790159e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9353, -0.8073,  0.9980],\n",
      "        [-0.7715, -0.8711,  0.9995],\n",
      "        [-0.6889, -0.6375,  0.9914],\n",
      "        [-0.7682, -0.5159,  0.9971]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7940_loss:  0.07166314125061035  critic_loss:  7.252414775393845e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9373, -0.8199,  0.9981],\n",
      "        [-0.7745, -0.8795,  0.9995],\n",
      "        [-0.6941, -0.6615,  0.9914],\n",
      "        [-0.7740, -0.5402,  0.9971]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7960_loss:  0.07093782722949982  critic_loss:  1.2819695029975264e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0185],\n",
      "        [-0.0153],\n",
      "        [-0.0155],\n",
      "        [-0.0182]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9354, -0.7939,  0.9986],\n",
      "        [-0.7713, -0.8613,  0.9996],\n",
      "        [-0.6856, -0.6143,  0.9938],\n",
      "        [-0.7629, -0.4863,  0.9979]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  7980_loss:  0.07153128832578659  critic_loss:  7.451633905475319e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0136],\n",
      "        [-0.0135],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9426, -0.8060,  0.9989],\n",
      "        [-0.8021, -0.8698,  0.9997],\n",
      "        [-0.6883, -0.6419,  0.9952],\n",
      "        [-0.7808, -0.5109,  0.9984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8000_loss:  0.07163086533546448  critic_loss:  7.257185643538833e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0171],\n",
      "        [-0.0139],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9426, -0.7939,  0.9985],\n",
      "        [-0.8065, -0.8662,  0.9996],\n",
      "        [-0.6940, -0.6376,  0.9936],\n",
      "        [-0.7914, -0.5077,  0.9978]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8020_loss:  0.07156038284301758  critic_loss:  7.217403776849096e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9438, -0.8197,  0.9983],\n",
      "        [-0.8044, -0.8837,  0.9995],\n",
      "        [-0.7075, -0.6725,  0.9925],\n",
      "        [-0.8039, -0.5490,  0.9974]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8040_loss:  0.07161987572908401  critic_loss:  7.122545184756746e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9457, -0.8170,  0.9982],\n",
      "        [-0.8082, -0.8826,  0.9995],\n",
      "        [-0.7147, -0.6693,  0.9918],\n",
      "        [-0.8114, -0.5436,  0.9972]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8060_loss:  0.07162299007177353  critic_loss:  7.0789815254102e-0777\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9483, -0.7989,  0.9981],\n",
      "        [-0.8116, -0.8703,  0.9995],\n",
      "        [-0.7189, -0.6461,  0.9913],\n",
      "        [-0.8173, -0.5144,  0.9970]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8080_loss:  0.07162781059741974  critic_loss:  7.03996477113833e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9475, -0.8148,  0.9979],\n",
      "        [-0.8083, -0.8794,  0.9994],\n",
      "        [-0.7132, -0.6562,  0.9906],\n",
      "        [-0.8140, -0.5265,  0.9968]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8100_loss:  0.07163222134113312  critic_loss:  7.003368409641553e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9486, -0.7928,  0.9979],\n",
      "        [-0.8094, -0.8652,  0.9994],\n",
      "        [-0.7123, -0.6281,  0.9905],\n",
      "        [-0.8157, -0.4898,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8120_loss:  0.0716312900185585  critic_loss:  6.967912327127124e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9538, -0.8213,  0.9978],\n",
      "        [-0.8250, -0.8810,  0.9994],\n",
      "        [-0.7258, -0.6584,  0.9903],\n",
      "        [-0.8331, -0.5268,  0.9966]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8140_loss:  0.07163307815790176  critic_loss:  6.933229315109202e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9537, -0.8262,  0.9979],\n",
      "        [-0.8267, -0.8823,  0.9994],\n",
      "        [-0.7256, -0.6606,  0.9907],\n",
      "        [-0.8332, -0.5320,  0.9968]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8160_loss:  0.07163409143686295  critic_loss:  6.8991340640423e-0707\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9572, -0.8038,  0.9979],\n",
      "        [-0.8349, -0.8669,  0.9994],\n",
      "        [-0.7325, -0.6328,  0.9905],\n",
      "        [-0.8412, -0.4969,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8180_loss:  0.07163459062576294  critic_loss:  6.86551231865451e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9571, -0.8147,  0.9976],\n",
      "        [-0.8355, -0.8729,  0.9993],\n",
      "        [-0.7330, -0.6450,  0.9895],\n",
      "        [-0.8418, -0.5147,  0.9963]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8200_loss:  0.07163619250059128  critic_loss:  6.832225381003809e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9593, -0.8344,  0.9976],\n",
      "        [-0.8437, -0.8846,  0.9993],\n",
      "        [-0.7458, -0.6634,  0.9894],\n",
      "        [-0.8497, -0.5421,  0.9963]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8220_loss:  0.0716024711728096  critic_loss:  6.812062451899692e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9607, -0.8175,  0.9976],\n",
      "        [-0.8486, -0.8740,  0.9993],\n",
      "        [-0.7525, -0.6437,  0.9893],\n",
      "        [-0.8535, -0.5166,  0.9962]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8240_loss:  0.07172214984893799  critic_loss:  7.000091954978416e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0130],\n",
      "        [-0.0131],\n",
      "        [-0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9587, -0.8082,  0.9981],\n",
      "        [-0.8449, -0.8692,  0.9995],\n",
      "        [-0.7339, -0.6214,  0.9917],\n",
      "        [-0.8408, -0.4785,  0.9970]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8260_loss:  0.07190966606140137  critic_loss:  7.831699235794076e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0172],\n",
      "        [-0.0140],\n",
      "        [-0.0140],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9610, -0.8106,  0.9988],\n",
      "        [-0.8547, -0.8800,  0.9997],\n",
      "        [-0.7332, -0.6334,  0.9951],\n",
      "        [-0.8437, -0.4849,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8280_loss:  0.07157530635595322  critic_loss:  6.867114734632196e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9641, -0.8166,  0.9983],\n",
      "        [-0.8627, -0.8795,  0.9995],\n",
      "        [-0.7569, -0.6447,  0.9926],\n",
      "        [-0.8577, -0.5087,  0.9974]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8300_loss:  0.07170868664979935  critic_loss:  6.799032803428418e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0138],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9644, -0.8270,  0.9979],\n",
      "        [-0.8625, -0.8857,  0.9994],\n",
      "        [-0.7703, -0.6583,  0.9908],\n",
      "        [-0.8643, -0.5272,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8320_loss:  0.071657694876194  critic_loss:  6.698899142065784e-0707\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9639, -0.8087,  0.9978],\n",
      "        [-0.8587, -0.8714,  0.9994],\n",
      "        [-0.7698, -0.6315,  0.9901],\n",
      "        [-0.8615, -0.4995,  0.9965]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8340_loss:  0.07165241986513138  critic_loss:  6.657009521404689e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9670, -0.8069,  0.9978],\n",
      "        [-0.8684, -0.8703,  0.9994],\n",
      "        [-0.7869, -0.6293,  0.9903],\n",
      "        [-0.8716, -0.4959,  0.9966]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8360_loss:  0.07165074348449707  critic_loss:  6.619990244871587e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9687, -0.8286,  0.9978],\n",
      "        [-0.8752, -0.8836,  0.9994],\n",
      "        [-0.7947, -0.6501,  0.9899],\n",
      "        [-0.8769, -0.5244,  0.9965]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8380_loss:  0.07164681702852249  critic_loss:  6.585418645954633e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9703, -0.8164,  0.9976],\n",
      "        [-0.8792, -0.8760,  0.9993],\n",
      "        [-0.7995, -0.6290,  0.9894],\n",
      "        [-0.8791, -0.5003,  0.9963]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8400_loss:  0.0716487467288971  critic_loss:  6.552093623213295e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9729, -0.8324,  0.9976],\n",
      "        [-0.8868, -0.8856,  0.9993],\n",
      "        [-0.8114, -0.6466,  0.9891],\n",
      "        [-0.8862, -0.5257,  0.9962]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8420_loss:  0.07164900004863739  critic_loss:  6.519449016195722e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9689, -0.8435,  0.9975],\n",
      "        [-0.8728, -0.8932,  0.9993],\n",
      "        [-0.7815, -0.6589,  0.9887],\n",
      "        [-0.8675, -0.5399,  0.9960]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8440_loss:  0.07164926826953888  critic_loss:  6.487366022156493e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9737, -0.8199,  0.9975],\n",
      "        [-0.8898, -0.8787,  0.9993],\n",
      "        [-0.8105, -0.6238,  0.9887],\n",
      "        [-0.8847, -0.5017,  0.9961]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8460_loss:  0.0716499611735344  critic_loss:  6.455792913584446e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9726, -0.8448,  0.9976],\n",
      "        [-0.8855, -0.8948,  0.9993],\n",
      "        [-0.7984, -0.6535,  0.9888],\n",
      "        [-0.8779, -0.5356,  0.9961]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8480_loss:  0.07165055721998215  critic_loss:  6.424675120797474e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9752, -0.8132,  0.9974],\n",
      "        [-0.8956, -0.8771,  0.9992],\n",
      "        [-0.8126, -0.6036,  0.9877],\n",
      "        [-0.8856, -0.4772,  0.9958]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8500_loss:  0.07165009528398514  critic_loss:  6.393885314537329e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9745, -0.8408,  0.9974],\n",
      "        [-0.8922, -0.8926,  0.9992],\n",
      "        [-0.8033, -0.6406,  0.9879],\n",
      "        [-0.8803, -0.5248,  0.9959]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8520_loss:  0.0712645947933197  critic_loss:  7.982625334079785e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0175],\n",
      "        [-0.0142],\n",
      "        [-0.0146],\n",
      "        [-0.0173]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9767, -0.8534,  0.9977],\n",
      "        [-0.9003, -0.9009,  0.9993],\n",
      "        [-0.8149, -0.6558,  0.9892],\n",
      "        [-0.8880, -0.5442,  0.9963]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8540_loss:  0.07252663373947144  critic_loss:  1.5026150776975555e-06\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0162],\n",
      "        [-0.0130],\n",
      "        [-0.0129],\n",
      "        [-0.0153]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9718, -0.7992,  0.9987],\n",
      "        [-0.8894, -0.8701,  0.9996],\n",
      "        [-0.7813, -0.5881,  0.9942],\n",
      "        [-0.8681, -0.4440,  0.9980]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8560_loss:  0.07157235592603683  critic_loss:  6.605205271625891e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0135],\n",
      "        [-0.0135],\n",
      "        [-0.0160]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9759, -0.8192,  0.9986],\n",
      "        [-0.8853, -0.9001,  0.9997],\n",
      "        [-0.8020, -0.6305,  0.9941],\n",
      "        [-0.8805, -0.5101,  0.9979]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8580_loss:  0.07153325527906418  critic_loss:  6.567499326592952e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0138],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9768, -0.8500,  0.9980],\n",
      "        [-0.8933, -0.9093,  0.9995],\n",
      "        [-0.8120, -0.6687,  0.9910],\n",
      "        [-0.8868, -0.5645,  0.9969]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8600_loss:  0.07170796394348145  critic_loss:  6.351228876155801e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0138],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9786, -0.8479,  0.9977],\n",
      "        [-0.9050, -0.9050,  0.9993],\n",
      "        [-0.8274, -0.6610,  0.9894],\n",
      "        [-0.8957, -0.5437,  0.9963]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8620_loss:  0.07166414707899094  critic_loss:  6.280484399212583e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0138],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9807, -0.8346,  0.9976],\n",
      "        [-0.9160, -0.8943,  0.9993],\n",
      "        [-0.8444, -0.6440,  0.9888],\n",
      "        [-0.9063, -0.5226,  0.9961]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8640_loss:  0.07165901362895966  critic_loss:  6.241261871764436e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9802, -0.8330,  0.9975],\n",
      "        [-0.9143, -0.8917,  0.9993],\n",
      "        [-0.8358, -0.6297,  0.9881],\n",
      "        [-0.9013, -0.5074,  0.9959]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8660_loss:  0.07166282087564468  critic_loss:  6.205725071595225e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0137],\n",
      "        [-0.0141],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9803, -0.8499,  0.9976],\n",
      "        [-0.9152, -0.9029,  0.9993],\n",
      "        [-0.8322, -0.6531,  0.9886],\n",
      "        [-0.9007, -0.5292,  0.9961]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8680_loss:  0.07166508585214615  critic_loss:  6.172404027893208e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0141],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9812, -0.8350,  0.9973],\n",
      "        [-0.9190, -0.8951,  0.9992],\n",
      "        [-0.8371, -0.6311,  0.9872],\n",
      "        [-0.9036, -0.5020,  0.9956]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8700_loss:  0.07166577130556107  critic_loss:  6.140431310086569e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0141],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9821, -0.8389,  0.9974],\n",
      "        [-0.9227, -0.8976,  0.9992],\n",
      "        [-0.8414, -0.6337,  0.9875],\n",
      "        [-0.9064, -0.5075,  0.9957]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8720_loss:  0.07166563719511032  critic_loss:  6.109376613494533e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0141],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9819, -0.8489,  0.9973],\n",
      "        [-0.9224, -0.9051,  0.9992],\n",
      "        [-0.8386, -0.6473,  0.9869],\n",
      "        [-0.9052, -0.5252,  0.9955]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8740_loss:  0.07166703790426254  critic_loss:  6.079005174797203e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9824, -0.8253,  0.9972],\n",
      "        [-0.9240, -0.8920,  0.9991],\n",
      "        [-0.8409, -0.6088,  0.9862],\n",
      "        [-0.9070, -0.4754,  0.9953]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8760_loss:  0.07166638225317001  critic_loss:  6.049129410712339e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0137],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9828, -0.8513,  0.9972],\n",
      "        [-0.9264, -0.9081,  0.9992],\n",
      "        [-0.8435, -0.6439,  0.9862],\n",
      "        [-0.9092, -0.5209,  0.9953]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8780_loss:  0.07166771590709686  critic_loss:  6.0196316553629e-0777\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9834, -0.8438,  0.9972],\n",
      "        [-0.9288, -0.9051,  0.9992],\n",
      "        [-0.8463, -0.6343,  0.9861],\n",
      "        [-0.9110, -0.5088,  0.9952]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8800_loss:  0.0716685876250267  critic_loss:  5.990405043121427e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0142],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9833, -0.8636,  0.9972],\n",
      "        [-0.9280, -0.9172,  0.9992],\n",
      "        [-0.8436, -0.6644,  0.9864],\n",
      "        [-0.9100, -0.5452,  0.9953]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8820_loss:  0.07167068123817444  critic_loss:  5.961472879789653e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0142],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9831, -0.8577,  0.9972],\n",
      "        [-0.9280, -0.9158,  0.9991],\n",
      "        [-0.8419, -0.6499,  0.9860],\n",
      "        [-0.9093, -0.5294,  0.9952]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8840_loss:  0.07186515629291534  critic_loss:  6.339288916024088e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0165],\n",
      "        [-0.0135],\n",
      "        [-0.0139],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9838, -0.8631,  0.9972],\n",
      "        [-0.9304, -0.9201,  0.9992],\n",
      "        [-0.8447, -0.6574,  0.9863],\n",
      "        [-0.9115, -0.5395,  0.9953]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8860_loss:  0.0727098137140274  critic_loss:  1.8245141291117761e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0161],\n",
      "        [-0.0130],\n",
      "        [-0.0130],\n",
      "        [-0.0155]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9819, -0.8119,  0.9982],\n",
      "        [-0.9251, -0.8909,  0.9995],\n",
      "        [-0.8279, -0.5879,  0.9916],\n",
      "        [-0.9013, -0.4519,  0.9971]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8880_loss:  0.07127402722835541  critic_loss:  7.570621392005705e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0171],\n",
      "        [-0.0140],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9837, -0.8452,  0.9985],\n",
      "        [-0.9240, -0.9222,  0.9996],\n",
      "        [-0.8358, -0.6318,  0.9933],\n",
      "        [-0.9070, -0.5061,  0.9977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8900_loss:  0.07181105017662048  critic_loss:  6.145330075923994e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0137],\n",
      "        [-0.0138],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9860, -0.8507,  0.9978],\n",
      "        [-0.9368, -0.9190,  0.9994],\n",
      "        [-0.8556, -0.6530,  0.9894],\n",
      "        [-0.9195, -0.5301,  0.9964]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8920_loss:  0.07168151438236237  critic_loss:  5.886411713618145e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0139],\n",
      "        [-0.0141],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9868, -0.8446,  0.9976],\n",
      "        [-0.9408, -0.9152,  0.9993],\n",
      "        [-0.8621, -0.6417,  0.9881],\n",
      "        [-0.9235, -0.5158,  0.9960]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8940_loss:  0.07167539745569229  critic_loss:  5.844103156960045e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0139],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9862, -0.8517,  0.9976],\n",
      "        [-0.9387, -0.9199,  0.9993],\n",
      "        [-0.8576, -0.6507,  0.9875],\n",
      "        [-0.9216, -0.5289,  0.9958]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8960_loss:  0.07168536633253098  critic_loss:  5.80853111387114e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9871, -0.8660,  0.9974],\n",
      "        [-0.9428, -0.9284,  0.9992],\n",
      "        [-0.8643, -0.6646,  0.9863],\n",
      "        [-0.9261, -0.5499,  0.9955]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  8980_loss:  0.07168302685022354  critic_loss:  5.776275315838575e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9862, -0.8545,  0.9974],\n",
      "        [-0.9384, -0.9234,  0.9992],\n",
      "        [-0.8537, -0.6457,  0.9864],\n",
      "        [-0.9199, -0.5278,  0.9955]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9000_loss:  0.07168058305978775  critic_loss:  5.745672524426482e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9864, -0.8423,  0.9973],\n",
      "        [-0.9389, -0.9181,  0.9992],\n",
      "        [-0.8520, -0.6189,  0.9860],\n",
      "        [-0.9192, -0.5008,  0.9954]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9020_loss:  0.07168157398700714  critic_loss:  5.716146915801801e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0142],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9868, -0.8592,  0.9970],\n",
      "        [-0.9412, -0.9269,  0.9991],\n",
      "        [-0.8575, -0.6447,  0.9839],\n",
      "        [-0.9224, -0.5343,  0.9947]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9040_loss:  0.07168153673410416  critic_loss:  5.687342081728275e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0142],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9878, -0.8402,  0.9972],\n",
      "        [-0.9449, -0.9187,  0.9992],\n",
      "        [-0.8668, -0.6203,  0.9848],\n",
      "        [-0.9274, -0.5046,  0.9950]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9060_loss:  0.07168258726596832  critic_loss:  5.6590636177134e-0777\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9875, -0.8528,  0.9972],\n",
      "        [-0.9445, -0.9267,  0.9992],\n",
      "        [-0.8640, -0.6367,  0.9848],\n",
      "        [-0.9261, -0.5257,  0.9950]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9080_loss:  0.0716833770275116  critic_loss:  5.631130761685199e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9866, -0.8703,  0.9972],\n",
      "        [-0.9409, -0.9350,  0.9992],\n",
      "        [-0.8535, -0.6553,  0.9850],\n",
      "        [-0.9207, -0.5530,  0.9950]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9100_loss:  0.0716862678527832  critic_loss:  5.603606041404419e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0138],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9872, -0.8533,  0.9971],\n",
      "        [-0.9433, -0.9269,  0.9992],\n",
      "        [-0.8591, -0.6323,  0.9841],\n",
      "        [-0.9235, -0.5275,  0.9948]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9120_loss:  0.072031170129776  critic_loss:  6.859455652374891e-0707\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0134],\n",
      "        [-0.0137],\n",
      "        [-0.0163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9873, -0.8472,  0.9971],\n",
      "        [-0.9435, -0.9242,  0.9991],\n",
      "        [-0.8578, -0.6187,  0.9837],\n",
      "        [-0.9230, -0.5144,  0.9946]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9140_loss:  0.07199060171842575  critic_loss:  6.84495830682863e-0766\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0174],\n",
      "        [-0.0144],\n",
      "        [-0.0145],\n",
      "        [-0.0170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9863, -0.8389,  0.9986],\n",
      "        [-0.9404, -0.9185,  0.9996],\n",
      "        [-0.8463, -0.6037,  0.9925],\n",
      "        [-0.9168, -0.4971,  0.9975]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9160_loss:  0.07166431099176407  critic_loss:  5.702503926841018e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0136],\n",
      "        [-0.0136],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9879, -0.8388,  0.9984],\n",
      "        [-0.9429, -0.9262,  0.9996],\n",
      "        [-0.8567, -0.6114,  0.9918],\n",
      "        [-0.9222, -0.5047,  0.9973]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9180_loss:  0.07174056768417358  critic_loss:  5.619031071546488e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0139],\n",
      "        [-0.0140],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9891, -0.8395,  0.9979],\n",
      "        [-0.9511, -0.9218,  0.9994],\n",
      "        [-0.8698, -0.6215,  0.9880],\n",
      "        [-0.9305, -0.5108,  0.9961]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9200_loss:  0.0716591477394104  critic_loss:  5.542696044358308e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0139],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9889, -0.8441,  0.9976],\n",
      "        [-0.9499, -0.9238,  0.9993],\n",
      "        [-0.8675, -0.6187,  0.9866],\n",
      "        [-0.9303, -0.5113,  0.9955]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9220_loss:  0.0716828852891922  critic_loss:  5.492193508871424e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0168],\n",
      "        [-0.0139],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9889, -0.8527,  0.9976],\n",
      "        [-0.9498, -0.9281,  0.9993],\n",
      "        [-0.8658, -0.6234,  0.9857],\n",
      "        [-0.9293, -0.5161,  0.9953]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9240_loss:  0.07169763743877411  critic_loss:  5.457081897475291e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9894, -0.8577,  0.9974],\n",
      "        [-0.9519, -0.9315,  0.9992],\n",
      "        [-0.8704, -0.6336,  0.9844],\n",
      "        [-0.9320, -0.5326,  0.9948]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9260_loss:  0.07169725745916367  critic_loss:  5.426452389656333e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9891, -0.8665,  0.9975],\n",
      "        [-0.9511, -0.9363,  0.9993],\n",
      "        [-0.8689, -0.6463,  0.9848],\n",
      "        [-0.9312, -0.5515,  0.9950]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9280_loss:  0.07169584184885025  critic_loss:  5.397324684963678e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0142],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9891, -0.8666,  0.9974],\n",
      "        [-0.9504, -0.9365,  0.9992],\n",
      "        [-0.8684, -0.6494,  0.9837],\n",
      "        [-0.9312, -0.5575,  0.9946]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9300_loss:  0.0716964602470398  critic_loss:  5.369188897930144e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9887, -0.8652,  0.9975],\n",
      "        [-0.9487, -0.9358,  0.9993],\n",
      "        [-0.8622, -0.6393,  0.9846],\n",
      "        [-0.9280, -0.5470,  0.9949]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9320_loss:  0.07169651985168457  critic_loss:  5.341831865735003e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9906, -0.8645,  0.9973],\n",
      "        [-0.9571, -0.9369,  0.9992],\n",
      "        [-0.8833, -0.6563,  0.9832],\n",
      "        [-0.9390, -0.5620,  0.9945]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9340_loss:  0.07169688493013382  critic_loss:  5.315026783137e-07707\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9904, -0.8698,  0.9973],\n",
      "        [-0.9557, -0.9393,  0.9992],\n",
      "        [-0.8770, -0.6520,  0.9831],\n",
      "        [-0.9362, -0.5632,  0.9944]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9360_loss:  0.07169798761606216  critic_loss:  5.288677584758261e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9891, -0.8650,  0.9975],\n",
      "        [-0.9493, -0.9353,  0.9992],\n",
      "        [-0.8592, -0.6393,  0.9837],\n",
      "        [-0.9268, -0.5508,  0.9946]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9380_loss:  0.07171313464641571  critic_loss:  5.265010827315564e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0138],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9903, -0.8798,  0.9976],\n",
      "        [-0.9551, -0.9437,  0.9993],\n",
      "        [-0.8719, -0.6637,  0.9841],\n",
      "        [-0.9340, -0.5808,  0.9947]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9400_loss:  0.07385960221290588  critic_loss:  5.327733106241794e-066\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0150],\n",
      "        [-0.0121],\n",
      "        [-0.0122],\n",
      "        [-0.0147]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9894, -0.8640,  0.9973],\n",
      "        [-0.9512, -0.9365,  0.9992],\n",
      "        [-0.8589, -0.6360,  0.9825],\n",
      "        [-0.9269, -0.5502,  0.9942]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9420_loss:  0.07198317348957062  critic_loss:  6.453786909332848e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0170],\n",
      "        [-0.0140],\n",
      "        [-0.0141],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9890, -0.8315,  0.9989],\n",
      "        [-0.9522, -0.9211,  0.9997],\n",
      "        [-0.8600, -0.5827,  0.9933],\n",
      "        [-0.9270, -0.4849,  0.9978]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9440_loss:  0.0715939998626709  critic_loss:  5.416026738203072e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0137],\n",
      "        [-0.0139],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9910, -0.8375,  0.9982],\n",
      "        [-0.9594, -0.9281,  0.9995],\n",
      "        [-0.8774, -0.6164,  0.9890],\n",
      "        [-0.9368, -0.5192,  0.9964]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9460_loss:  0.07178354263305664  critic_loss:  5.303274406287528e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0141],\n",
      "        [-0.0167]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9915, -0.8538,  0.9978],\n",
      "        [-0.9614, -0.9363,  0.9993],\n",
      "        [-0.8812, -0.6267,  0.9858],\n",
      "        [-0.9403, -0.5355,  0.9953]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9480_loss:  0.07173722237348557  critic_loss:  5.195436187932501e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0142],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9917, -0.8453,  0.9977],\n",
      "        [-0.9615, -0.9320,  0.9993],\n",
      "        [-0.8802, -0.6028,  0.9849],\n",
      "        [-0.9402, -0.5138,  0.9949]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9500_loss:  0.07171943783760071  critic_loss:  5.153900701770908e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9915, -0.8562,  0.9976],\n",
      "        [-0.9608, -0.9367,  0.9993],\n",
      "        [-0.8779, -0.6185,  0.9836],\n",
      "        [-0.9388, -0.5287,  0.9945]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9520_loss:  0.07170688360929489  critic_loss:  5.122829520587402e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9910, -0.8814,  0.9977],\n",
      "        [-0.9578, -0.9472,  0.9993],\n",
      "        [-0.8676, -0.6484,  0.9843],\n",
      "        [-0.9343, -0.5689,  0.9946]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9540_loss:  0.0717099979519844  critic_loss:  5.094722723697487e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9921, -0.8664,  0.9976],\n",
      "        [-0.9628, -0.9416,  0.9993],\n",
      "        [-0.8808, -0.6300,  0.9832],\n",
      "        [-0.9407, -0.5481,  0.9943]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9560_loss:  0.0717083290219307  critic_loss:  5.06789490373194e-0707\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9919, -0.8794,  0.9978],\n",
      "        [-0.9618, -0.9468,  0.9993],\n",
      "        [-0.8768, -0.6416,  0.9842],\n",
      "        [-0.9393, -0.5670,  0.9946]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9580_loss:  0.07170871645212173  critic_loss:  5.04190154515527e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9911, -0.8759,  0.9976],\n",
      "        [-0.9570, -0.9449,  0.9993],\n",
      "        [-0.8626, -0.6334,  0.9827],\n",
      "        [-0.9317, -0.5591,  0.9941]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9600_loss:  0.07170960307121277  critic_loss:  5.016543127567274e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9913, -0.8756,  0.9977],\n",
      "        [-0.9580, -0.9448,  0.9993],\n",
      "        [-0.8655, -0.6390,  0.9833],\n",
      "        [-0.9337, -0.5697,  0.9943]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9620_loss:  0.07170995324850082  critic_loss:  4.991581477042928e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9917, -0.8629,  0.9976],\n",
      "        [-0.9602, -0.9411,  0.9992],\n",
      "        [-0.8718, -0.6175,  0.9821],\n",
      "        [-0.9361, -0.5433,  0.9939]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9640_loss:  0.07170851528644562  critic_loss:  4.966931896888127e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0144],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9919, -0.8650,  0.9977],\n",
      "        [-0.9610, -0.9418,  0.9993],\n",
      "        [-0.8736, -0.6251,  0.9828],\n",
      "        [-0.9373, -0.5525,  0.9941]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9660_loss:  0.07137183845043182  critic_loss:  6.177667728479719e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0172],\n",
      "        [-0.0144],\n",
      "        [-0.0149],\n",
      "        [-0.0175]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9913, -0.8665,  0.9979],\n",
      "        [-0.9575, -0.9419,  0.9993],\n",
      "        [-0.8629, -0.6215,  0.9840],\n",
      "        [-0.9320, -0.5514,  0.9945]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9680_loss:  0.07175217568874359  critic_loss:  5.244477279120474e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0163],\n",
      "        [-0.0133],\n",
      "        [-0.0134],\n",
      "        [-0.0158]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9907, -0.8511,  0.9988],\n",
      "        [-0.9576, -0.9343,  0.9996],\n",
      "        [-0.8589, -0.5952,  0.9916],\n",
      "        [-0.9293, -0.5124,  0.9972]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9700_loss:  0.07141613960266113  critic_loss:  5.954485686743283e-076\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0171],\n",
      "        [-0.0141],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9916, -0.8559,  0.9988],\n",
      "        [-0.9593, -0.9439,  0.9997],\n",
      "        [-0.8685, -0.6092,  0.9919],\n",
      "        [-0.9349, -0.5344,  0.9974]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9720_loss:  0.07182728499174118  critic_loss:  5.10887161908613e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0166],\n",
      "        [-0.0138],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9929, -0.8626,  0.9981],\n",
      "        [-0.9675, -0.9444,  0.9994],\n",
      "        [-0.8832, -0.6277,  0.9861],\n",
      "        [-0.9432, -0.5504,  0.9954]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9740_loss:  0.07172790169715881  critic_loss:  4.913660518468532e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0140],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9932, -0.8569,  0.9979],\n",
      "        [-0.9684, -0.9417,  0.9993],\n",
      "        [-0.8880, -0.6061,  0.9840],\n",
      "        [-0.9458, -0.5279,  0.9946]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9760_loss:  0.07171543687582016  critic_loss:  4.874438559454575e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0140],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9930, -0.8603,  0.9979],\n",
      "        [-0.9673, -0.9424,  0.9993],\n",
      "        [-0.8866, -0.6063,  0.9830],\n",
      "        [-0.9453, -0.5309,  0.9942]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9780_loss:  0.07172303646802902  critic_loss:  4.842767680202087e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9929, -0.8591,  0.9977],\n",
      "        [-0.9662, -0.9420,  0.9993],\n",
      "        [-0.8840, -0.5998,  0.9818],\n",
      "        [-0.9441, -0.5239,  0.9937]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9800_loss:  0.07172319293022156  critic_loss:  4.814770022676385e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0143],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9926, -0.8787,  0.9978],\n",
      "        [-0.9649, -0.9500,  0.9993],\n",
      "        [-0.8784, -0.6297,  0.9818],\n",
      "        [-0.9417, -0.5609,  0.9937]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9820_loss:  0.07172077894210815  critic_loss:  4.788570890923438e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0144],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9930, -0.8875,  0.9978],\n",
      "        [-0.9668, -0.9534,  0.9993],\n",
      "        [-0.8829, -0.6390,  0.9820],\n",
      "        [-0.9440, -0.5724,  0.9937]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9840_loss:  0.07172223925590515  critic_loss:  4.763487027048541e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0144],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9928, -0.8618,  0.9977],\n",
      "        [-0.9648, -0.9422,  0.9993],\n",
      "        [-0.8777, -0.5921,  0.9814],\n",
      "        [-0.9412, -0.5208,  0.9935]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9860_loss:  0.07172118872404099  critic_loss:  4.738998029552022e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0144],\n",
      "        [-0.0169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9931, -0.8702,  0.9977],\n",
      "        [-0.9670, -0.9465,  0.9993],\n",
      "        [-0.8829, -0.6065,  0.9810],\n",
      "        [-0.9432, -0.5351,  0.9934]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9880_loss:  0.07172217220067978  critic_loss:  4.7149649162747664e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0144],\n",
      "        [-0.0170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9926, -0.8837,  0.9977],\n",
      "        [-0.9640, -0.9512,  0.9993],\n",
      "        [-0.8701, -0.6252,  0.9812],\n",
      "        [-0.9379, -0.5625,  0.9934]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9900_loss:  0.07172203063964844  critic_loss:  4.69135699177059e-0777\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0144],\n",
      "        [-0.0170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9931, -0.8818,  0.9978],\n",
      "        [-0.9661, -0.9500,  0.9993],\n",
      "        [-0.8785, -0.6231,  0.9812],\n",
      "        [-0.9418, -0.5601,  0.9934]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9920_loss:  0.07172118872404099  critic_loss:  4.6680904119966726e-07\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0167],\n",
      "        [-0.0139],\n",
      "        [-0.0144],\n",
      "        [-0.0170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9928, -0.8859,  0.9980],\n",
      "        [-0.9649, -0.9519,  0.9994],\n",
      "        [-0.8724, -0.6220,  0.9833],\n",
      "        [-0.9393, -0.5597,  0.9941]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9940_loss:  0.07159885764122009  critic_loss:  4.808657649846282e-077\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0169],\n",
      "        [-0.0141],\n",
      "        [-0.0146],\n",
      "        [-0.0172]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9931, -0.8827,  0.9978],\n",
      "        [-0.9659, -0.9495,  0.9993],\n",
      "        [-0.8750, -0.6145,  0.9817],\n",
      "        [-0.9406, -0.5543,  0.9936]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9960_loss:  0.0713830292224884  critic_loss:  5.921008892073587e-0706\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0177],\n",
      "        [-0.0147],\n",
      "        [-0.0150],\n",
      "        [-0.0176]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9920, -0.8609,  0.9988],\n",
      "        [-0.9604, -0.9361,  0.9997],\n",
      "        [-0.8502, -0.5824,  0.9905],\n",
      "        [-0.9282, -0.5121,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---> with i =  9980_loss:  0.0719512477517128  critic_loss:  5.472267616823956e-0776\n",
      "-> before normalization\n",
      "obs:  [[ 0.11845589  1.06622791  0.26689953 -0.00337579  1.01669633  0.3895826\n",
      "  -0.12183168 -0.04953158  0.12268308  0.12302905 -0.05231395  0.00597368]\n",
      " [ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08762034  1.04618073  0.2930907   0.0068996   1.01822054  0.3895826\n",
      "  -0.08072074 -0.02796018  0.0964919   0.0051654  -0.0195103   0.02986401]\n",
      " [ 0.09425674  1.03389931  0.28191781  0.00346652  1.01329958  0.3895826\n",
      "  -0.09079023 -0.02059972  0.10766479  0.00775347 -0.02354849  0.0200007 ]]\n",
      "g:  [[-0.00337579  1.01669633  0.3895826 ]\n",
      " [ 0.00138166  1.01722634  0.3895826 ]\n",
      " [ 0.0068996   1.01822054  0.3895826 ]\n",
      " [ 0.00346652  1.01329958  0.3895826 ]]\n",
      "obs_next:  [[ 0.10269233  1.07811856  0.25950855  0.00138166  1.01722634  0.3895826\n",
      "  -0.10131067 -0.06089222  0.13007405  0.04154824 -0.09115822  0.07767981]\n",
      " [ 0.08735173  1.04735661  0.29274386  0.00607914  1.01875627  0.3895826\n",
      "  -0.08127259 -0.02860034  0.09683874  0.00974636  0.05770168  0.00306431]\n",
      " [ 0.09438314  1.03201056  0.28263515  0.00507148  1.01673996  0.3895826\n",
      "  -0.08931166 -0.01527059  0.10694745  0.0036955  -0.02710276  0.02625316]\n",
      " [ 0.12010249  1.01422274  0.26925159  0.00535211  1.00648749  0.3895826\n",
      "  -0.11475038 -0.00773525  0.12033102  0.00558212 -0.04552205  0.02381365]]\n",
      "g_next:  [[0.00138166 1.01722634 0.3895826 ]\n",
      " [0.00607914 1.01875627 0.3895826 ]\n",
      " [0.00507148 1.01673996 0.3895826 ]\n",
      " [0.00535211 1.00648749 0.3895826 ]]\n",
      "-> after normalization\n",
      "obs_norm:  [[ 0.55487482  0.48945708  0.22968841 -0.38973181  0.78736961 -1.29651767\n",
      "  -0.5647188   0.54769025 -1.17502706  0.19285424 -0.35231587 -0.14012488]\n",
      " [ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.36114048  0.37018485  0.41470533 -0.36448565  0.79103246 -1.29651767\n",
      "  -0.47070365  0.59583821 -1.28490607 -0.24768903 -0.28305114 -0.06960761]\n",
      " [ 0.40283584  0.29711564  0.33577898 -0.37292058  0.77920683 -1.29651767\n",
      "  -0.49373121  0.61226696 -1.2380328  -0.23801551 -0.29157776 -0.09872123]]\n",
      "g_norm:  [[-0.38973181  0.78736961 -1.29651767]\n",
      " [-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36448565  0.79103246 -1.29651767]\n",
      " [-0.37292058  0.77920683 -1.29651767]]\n",
      "obs_next_norm:  [[ 0.45583514  0.56020138  0.17747786 -0.37804299  0.78864327 -1.29651767\n",
      "  -0.51779004  0.52233297 -1.14401993 -0.11169956 -0.43433535  0.07153066]\n",
      " [ 0.35945286  0.37718084  0.41225523 -0.36650148  0.79231987 -1.29651767\n",
      "  -0.47196565  0.59440937 -1.28345099 -0.23056661 -0.12001843 -0.14871249]\n",
      " [ 0.40362994  0.28587837  0.34084635 -0.36897727  0.78747446 -1.29651767\n",
      "  -0.49034992  0.62416174 -1.24104224 -0.25318313 -0.29908258 -0.08026579]\n",
      " [ 0.56522012  0.18004846  0.24630358 -0.36828778  0.76283658 -1.29651767\n",
      "  -0.54852483  0.64098082 -1.18489458 -0.24613145 -0.33797481 -0.0874665 ]]\n",
      "g_next_norm:  [[-0.37804299  0.78864327 -1.29651767]\n",
      " [-0.36650148  0.79231987 -1.29651767]\n",
      " [-0.36897727  0.78747446 -1.29651767]\n",
      " [-0.36828778  0.76283658 -1.29651767]]\n",
      "target_q_value  (r_tensor):  tensor([[-0.0176],\n",
      "        [-0.0130],\n",
      "        [-0.0140],\n",
      "        [-0.0166]], device='cuda:0') , real_q_value:  tensor([[-0.0164],\n",
      "        [-0.0134],\n",
      "        [-0.0135],\n",
      "        [-0.0161]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "actions_real:  tensor([[-0.9930, -0.8414,  0.9989],\n",
      "        [-0.9692, -0.9341,  0.9997],\n",
      "        [-0.8808, -0.5672,  0.9915],\n",
      "        [-0.9425, -0.4862,  0.9972]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "batch:  9999  actor_loss:  0.07163169980049133  critic_loss:  4.778520974468847e-07\r"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from mpi_utils.normalizer import normalizer\n",
    "import torch\n",
    "from rl_modules.models import actor, critic\n",
    "from mpi_utils.mpi_utils import sync_networks, sync_grads\n",
    "from her_modules.her import her_sampler\n",
    "from rl_modules.replay_buffer import replay_buffer\n",
    "\n",
    "REWARD_SCALE = 10.0\n",
    "\n",
    "def _goal_distance(goal_a, goal_b):\n",
    "    assert goal_a.shape == goal_b.shape\n",
    "    return np.linalg.norm(goal_a - goal_b, axis=-1)\n",
    "\n",
    "def compute_reward(achieved_goal, desired_goal, info=None, reward_type=\"dense\", max_reward=1.0):\n",
    "    distance = _goal_distance(achieved_goal, desired_goal)\n",
    "    reward = -distance.astype(np.float32)/REWARD_SCALE\n",
    "    return reward\n",
    "    \n",
    "def _preproc_og(o, g):\n",
    "    o = np.clip(o, -200, 200)\n",
    "    g = np.clip(g, -200, 200)\n",
    "    return o, g\n",
    "    \n",
    "def _update_network(transitions, \n",
    "                    o_norm_, \n",
    "                    g_norm_, \n",
    "                    actor_optim, \n",
    "                    critic_optim, \n",
    "                    actor_network, \n",
    "                    critic_network, \n",
    "                    i,\n",
    "                    cuda=False):\n",
    "    # pre-process the observation and goal\n",
    "    o, o_next, g, g_next = transitions['obs'], transitions['obs_next'], transitions['g'], transitions['g_next']\n",
    "    transitions['obs'], transitions['g'] = _preproc_og(o, g)\n",
    "    transitions['obs_next'], transitions['g_next'] = _preproc_og(o_next, g_next)\n",
    "\n",
    "    # start to do the update\n",
    "    obs_norm = o_norm_.normalize(transitions['obs'])\n",
    "    g_norm = g_norm_.normalize(transitions['g'])\n",
    "    inputs_norm = np.concatenate([obs_norm, g_norm], axis=1)\n",
    "    obs_next_norm = o_norm_.normalize(transitions['obs_next'])\n",
    "    g_next_norm = g_norm_.normalize(transitions['g_next'])\n",
    "    inputs_next_norm = np.concatenate([obs_next_norm, g_next_norm], axis=1)\n",
    "\n",
    "    if i%20 == 0:\n",
    "        print('---> with i = ', i)\n",
    "        print('-> before normalization')\n",
    "        print('obs: ', o[:4])\n",
    "        print('g: ', g[:4])\n",
    "        print('obs_next: ', o_next[:4])\n",
    "        print('g_next: ', g_next[:4])\n",
    "        print('-> after normalization')\n",
    "        print('obs_norm: ', obs_norm[:4])\n",
    "        print('g_norm: ', g_norm[:4])\n",
    "        print('obs_next_norm: ', obs_next_norm[:4])\n",
    "        print('g_next_norm: ', g_next_norm[:4])\n",
    "\n",
    "    # transfer them into the tensor\n",
    "    inputs_norm_tensor = torch.tensor(inputs_norm, dtype=torch.float32)\n",
    "    inputs_next_norm_tensor = torch.tensor(inputs_next_norm, dtype=torch.float32)\n",
    "    actions_tensor = torch.tensor(transitions['actions'], dtype=torch.float32)\n",
    "    r_tensor = torch.tensor(transitions['r'], dtype=torch.float32) \n",
    "\n",
    "    if cuda:\n",
    "        inputs_norm_tensor = inputs_norm_tensor.cuda()\n",
    "        inputs_next_norm_tensor = inputs_next_norm_tensor.cuda()\n",
    "        actions_tensor = actions_tensor.cuda()\n",
    "        r_tensor = r_tensor.cuda()\n",
    "\n",
    "    # calculate the target Q value function\n",
    "    with torch.no_grad():\n",
    "        gamma = 0.98\n",
    "        target_q_value = r_tensor\n",
    "        target_q_value = target_q_value.detach()\n",
    "\n",
    "        # clip the q value\n",
    "        clip_return = 1 / (1 - gamma)\n",
    "        target_q_value = torch.clamp(target_q_value, -clip_return, 0)\n",
    "\n",
    "    # the q loss\n",
    "    real_q_value = critic_network(inputs_norm_tensor, actions_tensor)\n",
    "    critic_loss = (target_q_value - real_q_value).pow(2).mean()\n",
    "\n",
    "    if i%20 == 0:\n",
    "        print('target_q_value  (r_tensor): ', r_tensor[:4], ', real_q_value: ', real_q_value[:4])\n",
    "\n",
    "    # the actor loss\n",
    "    actions_real = actor_network(inputs_norm_tensor)\n",
    "    actor_loss = -critic_network(inputs_norm_tensor, actions_real).mean()\n",
    "    action_l2 = 1\n",
    "    action_max = 1\n",
    "    actor_loss += action_l2 * (actions_real / action_max).pow(2).mean()\n",
    "\n",
    "    if i%20 == 0:\n",
    "        print('actions_real: ', actions_real[:4])\n",
    "\n",
    "    # start to update the network\n",
    "    actor_optim.zero_grad()\n",
    "    actor_loss.backward()\n",
    "    sync_grads(actor_network)\n",
    "    actor_optim.step()\n",
    "\n",
    "    # update the critic_network\n",
    "    critic_optim.zero_grad()\n",
    "    critic_loss.backward()\n",
    "    sync_grads(critic_network)\n",
    "    critic_optim.step()\n",
    "\n",
    "    # print('actor_loss: ', actor_loss.item(), 'critic_loss: ', critic_loss.item(), end='\\r')\n",
    "    return actor_loss.item(), critic_loss.item()\n",
    "\n",
    "# update the normalizer\n",
    "def _update_normalizer(transitions, o_norm, g_norm):\n",
    "    mb_obs, mb_ag, mb_g, mb_actions, mb_rewards, mb_obs_next, mb_ag_next, mb_g_next = transitions\n",
    "\n",
    "    # create the new buffer to store them\n",
    "    transitions = {'obs': mb_obs, \n",
    "                    'ag': mb_ag,\n",
    "                    'g': mb_g, \n",
    "                    'actions': mb_actions, \n",
    "                    'obs_next': mb_obs_next,\n",
    "                    'ag_next': mb_ag_next,\n",
    "                    'g_next': mb_g_next,\n",
    "                    'r': mb_rewards\n",
    "                    }\n",
    "    \n",
    "    obs, g = transitions['obs'], transitions['g']\n",
    "    obs_next, g_next = transitions['obs_next'], transitions['g_next']\n",
    "\n",
    "    # pre process the obs and g\n",
    "    transitions['obs'], transitions['g'] = _preproc_og(obs, g)\n",
    "\n",
    "    # pre process the obs_next and g_next\n",
    "    transitions['obs_next'], transitions['g_next'] = _preproc_og(obs_next, g_next)\n",
    "\n",
    "    # update\n",
    "    o_norm.update(transitions['obs'])\n",
    "    g_norm.update(transitions['g'])\n",
    "    o_norm.update(transitions['obs_next'])\n",
    "    g_norm.update(transitions['g_next'])\n",
    "\n",
    "    # recompute the stats\n",
    "    o_norm.recompute_stats()\n",
    "    g_norm.recompute_stats()\n",
    "\n",
    "def _soft_update_target_network(target, source, polyak):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_((1 - polyak) * param.data + polyak * target_param.data)\n",
    "\n",
    "def sample_her_transitions(transitions, replay_k):\n",
    "    future_p = 1 - (1. / (1 + replay_k))\n",
    "    rollout_batch_size = transitions['actions'].shape[0]\n",
    "\n",
    "    # her idx\n",
    "    her_indexes = np.where(np.random.uniform(size=rollout_batch_size) < future_p)\n",
    "\n",
    "    # replace goal with achieved goal\n",
    "    future_ag = transitions['ag'][her_indexes]\n",
    "    transitions['g'][her_indexes] = future_ag\n",
    "    transitions['g_next'][her_indexes] = future_ag\n",
    "\n",
    "    # to get the params to re-compute reward\n",
    "    transitions['r'] = np.expand_dims(compute_reward(transitions['ag_next'], transitions['g_next'], None), 1)\n",
    "    transitions = {k: transitions[k].reshape(rollout_batch_size, *transitions[k].shape[1:]) for k in transitions.keys()}\n",
    "\n",
    "    return transitions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nessary params for the training\n",
    "env_params = {\n",
    "    'obs': 12, # size of observation\n",
    "    'goal': 3, # size of goal\n",
    "    'action': 3, # size of action\n",
    "    'action_max': 1, # max value of action\n",
    "    'max_timesteps': 25 # max value of timesteps in one episode\n",
    "}\n",
    "learning_rate = 0.001\n",
    "n_batches = 10000\n",
    "replay_k = 2 # if the HER sampler is used\n",
    "cuda = True\n",
    "polyak = 0.0001 # since the generated data is much more than the original data, so we use a small polyak to overfit the data\n",
    "\n",
    "# create the normalizer\n",
    "o_norm = normalizer(size=env_params['obs'], default_clip_range=5)\n",
    "g_norm = normalizer(size=env_params['goal'], default_clip_range=5)\n",
    "\n",
    "# create the network\n",
    "actor_network = actor(env_params)\n",
    "critic_network = critic(env_params)\n",
    "\n",
    "# load the model\n",
    "o_mean, o_std, g_mean, g_std, actor_model, critic_model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "o_norm.mean = o_mean\n",
    "o_norm.std = o_std\n",
    "g_norm.mean = g_mean\n",
    "g_norm.std = g_std\n",
    "actor_network.load_state_dict(actor_model)\n",
    "critic_network.load_state_dict(critic_model)\n",
    "\n",
    "# sync the network\n",
    "sync_networks(actor_network)\n",
    "sync_networks(critic_network)\n",
    "\n",
    "# build up the target network\n",
    "actor_target_network = actor(env_params)\n",
    "critic_target_network = critic(env_params)\n",
    "\n",
    "# if use gpu\n",
    "actor_network.cuda()\n",
    "critic_network.cuda()\n",
    "actor_target_network.cuda()\n",
    "critic_target_network.cuda()\n",
    "\n",
    "# load the weights into the target networks\n",
    "actor_target_network.load_state_dict(actor_network.state_dict())\n",
    "critic_target_network.load_state_dict(critic_network.state_dict())\n",
    "\n",
    "actor_optim = torch.optim.Adam(actor_network.parameters(), lr=learning_rate)\n",
    "critic_optim = torch.optim.Adam(critic_network.parameters(), lr=learning_rate)\n",
    "\n",
    "# obs, ag, g, actions, rewards, obs_next, ag_next\n",
    "transitions = [new_data[:, 0:12], \n",
    "               new_data[:, 12:15], \n",
    "               new_data[:, 15:18], \n",
    "               new_data[:, 18:21], \n",
    "               new_data[:, 21:22], \n",
    "               new_data[:, 22:34], \n",
    "               new_data[:, 34:37],\n",
    "               new_data[:, 37:40]]\n",
    "\n",
    "# update the normalizer\n",
    "_update_normalizer(transitions, o_norm, g_norm)\n",
    "\n",
    "mb_obs, mb_ag, mb_g, mb_actions, mb_rewards, mb_obs_next, mb_ag_next, mb_g_next = transitions\n",
    "transitions = {'obs': mb_obs, \n",
    "                'ag': mb_ag,\n",
    "                'g': mb_g, \n",
    "                'actions': mb_actions, \n",
    "                'obs_next': mb_obs_next,\n",
    "                'ag_next': mb_ag_next,\n",
    "                'g_next': mb_g_next,\n",
    "                'r': mb_rewards\n",
    "                }\n",
    "\n",
    "# her sampler\n",
    "if her_used:\n",
    "    transitions = sample_her_transitions(transitions, replay_k)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "for i in range(n_batches):\n",
    "    actor_loss, critic_loss = _update_network(transitions, \n",
    "                                              o_norm, \n",
    "                                              g_norm, \n",
    "                                              actor_optim, \n",
    "                                              critic_optim, \n",
    "                                              actor_network, \n",
    "                                              critic_network, \n",
    "                                              i,\n",
    "                                              cuda=cuda)\n",
    "    writer.add_scalar('actor_loss', actor_loss, i)\n",
    "    writer.add_scalar('critic_loss', critic_loss, i)\n",
    "    _soft_update_target_network(actor_target_network, actor_network, polyak)\n",
    "    _soft_update_target_network(critic_target_network, critic_network, polyak)\n",
    "    print('batch: ', i, ' actor_loss: ', actor_loss, ' critic_loss: ', critic_loss, end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "training_label = 'default'\n",
    "model_path = 'saved_models/RefinedUnderwaterEnv'\n",
    "torch.save([o_norm.mean, o_norm.std, g_norm.mean, g_norm.std, actor_network.state_dict(), critic_network.state_dict()], \\\n",
    "            model_path + f'/model_{training_label}_{date}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
